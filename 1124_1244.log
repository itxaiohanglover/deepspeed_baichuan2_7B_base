[2023-11-24 04:50:21,058] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)===================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please runpython -m bitsandbytes and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues================================================================================bin /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.soCUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.soCUDA SETUP: Highest compute capability among GPUs detected: 8.0CUDA SETUP: Detected CUDA version 118CUDA SETUP: Loading binary /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...[2023-11-24 04:50:22,815] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.Detected CUDA_VISIBLE_DEVICES=0,1,2 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.[2023-11-24 04:50:22,815] [INFO] [runner.py:555:main] cmd = /usr/local/miniconda3/envs/llm_env/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMl19 --master_addr=127.0.0.1 --master_port=65224 --enable_each_rank_log=None train.py --train_args_file /hy-tmp/autodl-tmp/artboy/finetune/llm_code/training_config/baichuan2_config.json[2023-11-24 04:50:24,164] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)===================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please runpython -m bitsandbytes and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues================================================================================bin /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/miniconda3/envs/llm_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...  warn(msg)CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths.../usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.Either way, this might cause trouble in the future:If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.  warn(msg)CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0CUDA SETUP: Highest compute capability among GPUs detected: 8.0CUDA SETUP: Detected CUDA version 118CUDA SETUP: Loading binary /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...[2023-11-24 04:50:25,678] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2]}[2023-11-24 04:50:25,679] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=3, node_rank=0[2023-11-24 04:50:25,679] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2]})[2023-11-24 04:50:25,679] [INFO] [launch.py:163:main] dist_world_size=3[2023-11-24 04:50:25,679] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2===================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please runpython -m bitsandbytes and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues===================================================================================================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please runpython -m bitsandbytes and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues===================================================================================================================BUG REPORT===================================Welcome to bitsandbytes. For bug reports, please runpython -m bitsandbytes and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues================================================================================bin /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/miniconda3/envs/llm_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...  warn(msg)CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths.../usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.Either way, this might cause trouble in the future:If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.  warn(msg)CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0CUDA SETUP: Highest compute capability among GPUs detected: 8.0CUDA SETUP: Detected CUDA version 118CUDA SETUP: Loading binary /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...bin /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/miniconda3/envs/llm_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...  warn(msg)CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths.../usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.Either way, this might cause trouble in the future:If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.  warn(msg)CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0CUDA SETUP: Highest compute capability among GPUs detected: 8.0CUDA SETUP: Detected CUDA version 118CUDA SETUP: Loading binary /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...bin /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/miniconda3/envs/llm_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...  warn(msg)CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths.../usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.Either way, this might cause trouble in the future:If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.  warn(msg)CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.soCUDA SETUP: Highest compute capability among GPUs detected: 8.0CUDA SETUP: Detected CUDA version 118CUDA SETUP: Loading binary /usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...[2023-11-24 04:50:28,417] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)[2023-11-24 04:50:28,426] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)[2023-11-24 04:50:28,432] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)[2023-11-24 04:50:29,166] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented[2023-11-24 04:50:29,166] [INFO] [comm.py:594:init_distributed] cdb=None[2023-11-24 04:50:29,206] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented[2023-11-24 04:50:29,206] [INFO] [comm.py:594:init_distributed] cdb=None[2023-11-24 04:50:29,297] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented[2023-11-24 04:50:29,297] [INFO] [comm.py:594:init_distributed] cdb=None[2023-11-24 04:50:29,297] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl2023-11-24 04:50:30.233 | INFO     | __main__:setup_everything:35 - train_args:TrainingArguments(_n_gpu=1,adafactor=False,adam_beta1=0.9,adam_beta2=0.999,adam_epsilon=1e-08,auto_find_batch_size=False,bf16=False,bf16_full_eval=False,data_seed=None,dataloader_drop_last=False,dataloader_num_workers=5,dataloader_pin_memory=True,ddp_backend=None,ddp_bucket_cap_mb=None,ddp_find_unused_parameters=None,ddp_timeout=1800,debug=[],deepspeed=/hy-tmp/autodl-tmp/artboy/finetune/llm_code/deepspeed_config/deepspeed_config.json,disable_tqdm=False,do_eval=False,do_predict=False,do_train=False,eval_accumulation_steps=None,eval_delay=0,eval_steps=None,evaluation_strategy=no,fp16=True,fp16_backend=auto,fp16_full_eval=False,fp16_opt_level=O1,fsdp=[],fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},fsdp_min_num_params=0,fsdp_transformer_layer_cls_to_wrap=None,full_determinism=False,gradient_accumulation_steps=4,gradient_checkpointing=False,greater_is_better=None,group_by_length=False,half_precision_backend=auto,hub_model_id=None,hub_private_repo=False,hub_strategy=every_save,hub_token=<HUB_TOKEN>,ignore_data_skip=False,include_inputs_for_metrics=False,jit_mode_eval=False,label_names=None,label_smoothing_factor=0.0,learning_rate=1e-05,length_column_name=length,load_best_model_at_end=False,local_rank=0,log_level=passive,log_level_replica=warning,log_on_each_node=True,logging_dir=./output/baichuan2-sft-1e5-1124/runs/Nov24_04-50-29_I1678c166a701b012d0,logging_first_step=False,logging_nan_inf_filter=True,logging_steps=10,logging_strategy=steps,lr_scheduler_type=cosine,max_grad_norm=1.0,max_steps=-1,metric_for_best_model=None,mp_parameters=,no_cuda=False,num_train_epochs=2,optim=adamw_hf,optim_args=None,output_dir=./output/baichuan2-sft-1e5-1124,overwrite_output_dir=False,past_index=-1,per_device_eval_batch_size=8,per_device_train_batch_size=12,prediction_loss_only=False,push_to_hub=False,push_to_hub_model_id=None,push_to_hub_organization=None,push_to_hub_token=<PUSH_TO_HUB_TOKEN>,ray_scope=last,remove_unused_columns=False,report_to=['tensorboard'],resume_from_checkpoint=None,run_name=./output/baichuan2-sft-1e5-1124,save_on_each_node=False,save_safetensors=False,save_steps=100,save_strategy=steps,save_total_limit=1,seed=42,sharded_ddp=[],skip_memory_metrics=True,tf32=None,torch_compile=False,torch_compile_backend=None,torch_compile_mode=None,torchdynamo=None,tpu_metrics_debug=False,tpu_num_cores=None,use_ipex=False,use_legacy_prediction_loop=False,use_mps_device=False,warmup_ratio=0.0,warmup_steps=200,weight_decay=0,xpu_backend=None,)2023-11-24 04:50:30.234 | INFO     | __main__:init_components:45 - Initializing components...2023-11-24 04:50:30.234 | INFO     | __main__:setup_everything:35 - train_args:TrainingArguments(_n_gpu=1,adafactor=False,adam_beta1=0.9,adam_beta2=0.999,adam_epsilon=1e-08,auto_find_batch_size=False,bf16=False,bf16_full_eval=False,data_seed=None,dataloader_drop_last=False,dataloader_num_workers=5,dataloader_pin_memory=True,ddp_backend=None,ddp_bucket_cap_mb=None,ddp_find_unused_parameters=None,ddp_timeout=1800,debug=[],deepspeed=/hy-tmp/autodl-tmp/artboy/finetune/llm_code/deepspeed_config/deepspeed_config.json,disable_tqdm=False,do_eval=False,do_predict=False,do_train=False,eval_accumulation_steps=None,eval_delay=0,eval_steps=None,evaluation_strategy=no,fp16=True,fp16_backend=auto,fp16_full_eval=False,fp16_opt_level=O1,fsdp=[],fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},fsdp_min_num_params=0,fsdp_transformer_layer_cls_to_wrap=None,full_determinism=False,gradient_accumulation_steps=4,gradient_checkpointing=False,greater_is_better=None,group_by_length=False,half_precision_backend=auto,hub_model_id=None,hub_private_repo=False,hub_strategy=every_save,hub_token=<HUB_TOKEN>,ignore_data_skip=False,include_inputs_for_metrics=False,jit_mode_eval=False,label_names=None,label_smoothing_factor=0.0,learning_rate=1e-05,length_column_name=length,load_best_model_at_end=False,local_rank=2,log_level=passive,log_level_replica=warning,log_on_each_node=True,logging_dir=./output/baichuan2-sft-1e5-1124/runs/Nov24_04-50-29_I1678c166a701b012d0,logging_first_step=False,logging_nan_inf_filter=True,logging_steps=10,logging_strategy=steps,lr_scheduler_type=cosine,max_grad_norm=1.0,max_steps=-1,metric_for_best_model=None,mp_parameters=,no_cuda=False,num_train_epochs=2,optim=adamw_hf,optim_args=None,output_dir=./output/baichuan2-sft-1e5-1124,overwrite_output_dir=False,past_index=-1,per_device_eval_batch_size=8,per_device_train_batch_size=12,prediction_loss_only=False,push_to_hub=False,push_to_hub_model_id=None,push_to_hub_organization=None,push_to_hub_token=<PUSH_TO_HUB_TOKEN>,ray_scope=last,remove_unused_columns=False,report_to=['tensorboard'],resume_from_checkpoint=None,run_name=./output/baichuan2-sft-1e5-1124,save_on_each_node=False,save_safetensors=False,save_steps=100,save_strategy=steps,save_total_limit=1,seed=42,sharded_ddp=[],skip_memory_metrics=True,tf32=None,torch_compile=False,torch_compile_backend=None,torch_compile_mode=None,torchdynamo=None,tpu_metrics_debug=False,tpu_num_cores=None,use_ipex=False,use_legacy_prediction_loop=False,use_mps_device=False,warmup_ratio=0.0,warmup_steps=200,weight_decay=0,xpu_backend=None,)2023-11-24 04:50:30.234 | INFO     | __main__:setup_everything:35 - train_args:TrainingArguments(_n_gpu=1,adafactor=False,adam_beta1=0.9,adam_beta2=0.999,adam_epsilon=1e-08,auto_find_batch_size=False,bf16=False,bf16_full_eval=False,data_seed=None,dataloader_drop_last=False,dataloader_num_workers=5,dataloader_pin_memory=True,ddp_backend=None,ddp_bucket_cap_mb=None,ddp_find_unused_parameters=None,ddp_timeout=1800,debug=[],deepspeed=/hy-tmp/autodl-tmp/artboy/finetune/llm_code/deepspeed_config/deepspeed_config.json,disable_tqdm=False,do_eval=False,do_predict=False,do_train=False,eval_accumulation_steps=None,eval_delay=0,eval_steps=None,evaluation_strategy=no,fp16=True,fp16_backend=auto,fp16_full_eval=False,fp16_opt_level=O1,fsdp=[],fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},fsdp_min_num_params=0,fsdp_transformer_layer_cls_to_wrap=None,full_determinism=False,gradient_accumulation_steps=4,gradient_checkpointing=False,greater_is_better=None,group_by_length=False,half_precision_backend=auto,hub_model_id=None,hub_private_repo=False,hub_strategy=every_save,hub_token=<HUB_TOKEN>,ignore_data_skip=False,include_inputs_for_metrics=False,jit_mode_eval=False,label_names=None,label_smoothing_factor=0.0,learning_rate=1e-05,length_column_name=length,load_best_model_at_end=False,local_rank=1,log_level=passive,log_level_replica=warning,log_on_each_node=True,logging_dir=./output/baichuan2-sft-1e5-1124/runs/Nov24_04-50-29_I1678c166a701b012d0,logging_first_step=False,logging_nan_inf_filter=True,logging_steps=10,logging_strategy=steps,lr_scheduler_type=cosine,max_grad_norm=1.0,max_steps=-1,metric_for_best_model=None,mp_parameters=,no_cuda=False,num_train_epochs=2,optim=adamw_hf,optim_args=None,output_dir=./output/baichuan2-sft-1e5-1124,overwrite_output_dir=False,past_index=-1,per_device_eval_batch_size=8,per_device_train_batch_size=12,prediction_loss_only=False,push_to_hub=False,push_to_hub_model_id=None,push_to_hub_organization=None,push_to_hub_token=<PUSH_TO_HUB_TOKEN>,ray_scope=last,remove_unused_columns=False,report_to=['tensorboard'],resume_from_checkpoint=None,run_name=./output/baichuan2-sft-1e5-1124,save_on_each_node=False,save_safetensors=False,save_steps=100,save_strategy=steps,save_total_limit=1,seed=42,sharded_ddp=[],skip_memory_metrics=True,tf32=None,torch_compile=False,torch_compile_backend=None,torch_compile_mode=None,torchdynamo=None,tpu_metrics_debug=False,tpu_num_cores=None,use_ipex=False,use_legacy_prediction_loop=False,use_mps_device=False,warmup_ratio=0.0,warmup_steps=200,weight_decay=0,xpu_backend=None,)2023-11-24 04:50:30.235 | INFO     | __main__:init_components:45 - Initializing components...2023-11-24 04:50:30.235 | INFO     | __main__:init_components:45 - Initializing components...[2023-11-24 04:50:39,323] [INFO] [partition_parameters.py:453:__exit__] finished initializing model with 7.51B parametersLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.65s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.65s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  8.00s/it]2023-11-24 04:50:55.376 | INFO     | __main__:init_components:88 - Total model params: 0.00M2023-11-24 04:50:55.376 | INFO     | component.dataset:__init__:12 - Loading data: /hy-tmp/autodl-tmp/artboy/finetune/llm_code/data/psychology_data.jsonlLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.01s/it]2023-11-24 04:50:55.420 | INFO     | __main__:init_components:88 - Total model params: 0.00M2023-11-24 04:50:55.420 | INFO     | component.dataset:__init__:12 - Loading data: /hy-tmp/autodl-tmp/artboy/finetune/llm_code/data/psychology_data.jsonl2023-11-24 04:50:55.458 | INFO     | __main__:init_components:88 - Total model params: 0.00M2023-11-24 04:50:55.458 | INFO     | component.dataset:__init__:12 - Loading data: /hy-tmp/autodl-tmp/artboy/finetune/llm_code/data/psychology_data.jsonl2023-11-24 04:50:55.550 | INFO     | component.dataset:__init__:15 - there are 77250 data in dataset2023-11-24 04:50:55.559 | INFO     | __main__:main:117 - *** starting training ***2023-11-24 04:50:55.595 | INFO     | component.dataset:__init__:15 - there are 77250 data in dataset2023-11-24 04:50:55.605 | INFO     | __main__:main:117 - *** starting training ***2023-11-24 04:50:55.661 | INFO     | component.dataset:__init__:15 - there are 77250 data in dataset2023-11-24 04:50:55.672 | INFO     | __main__:main:117 - *** starting training ***Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationUsing /root/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationUsing /root/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...Installed CUDA version 11.8 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationUsing /root/.cache/torch_extensions/py38_cu117 as PyTorch extensions root...Detected CUDA files, patching ldflagsEmitting ninja build file /root/.cache/torch_extensions/py38_cu117/cpu_adam/build.ninja...Building extension module cpu_adam...Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)ninja: no work to do.Loading extension module cpu_adam...Time to load cpu_adam op: 3.156536102294922 secondsLoading extension module cpu_adam...Time to load cpu_adam op: 3.011915445327759 secondsLoading extension module cpu_adam...Time to load cpu_adam op: 3.136136531829834 secondsParameter Offload: Total persistent parameters: 266240 in 65 params  0%|          | 0/1072 [00:00<?, ?it/s]/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()  0%|          | 1/1072 [00:35<10:35:13, 35.59s/it]  0%|          | 2/1072 [01:06<9:46:03, 32.86s/it]   0%|          | 3/1072 [01:37<9:27:27, 31.85s/it]  0%|          | 4/1072 [02:08<9:21:50, 31.56s/it]  0%|          | 5/1072 [02:39<9:15:43, 31.25s/it]  1%|          | 6/1072 [03:09<9:11:13, 31.03s/it]  1%|          | 7/1072 [03:40<9:07:26, 30.84s/it]  1%|          | 8/1072 [04:10<9:06:37, 30.82s/it]  1%|          | 9/1072 [04:40<9:01:16, 30.55s/it]  1%|          | 10/1072 [05:11<8:59:48, 30.50s/it]tried to get lr value before scheduler/optimizer started stepping, returning lr=0tried to get lr value before scheduler/optimizer started stepping, returning lr=0tried to get lr value before scheduler/optimizer started stepping, returning lr=0                                                   {'loss': 3.0163, 'learning_rate': 0, 'epoch': 0.02}  1%|          | 10/1072 [05:11<8:59:48, 30.50s/it]  1%|          | 11/1072 [05:59<10:35:13, 35.92s/it]  1%|          | 12/1072 [06:36<10:39:34, 36.20s/it]  1%|          | 13/1072 [07:12<10:39:14, 36.22s/it]  1%|▏         | 14/1072 [07:48<10:37:59, 36.18s/it]  1%|▏         | 15/1072 [08:24<10:35:32, 36.08s/it]  1%|▏         | 16/1072 [09:00<10:35:24, 36.10s/it]  2%|▏         | 17/1072 [09:36<10:31:42, 35.93s/it]  2%|▏         | 18/1072 [10:11<10:30:46, 35.91s/it]  2%|▏         | 19/1072 [10:48<10:31:38, 35.99s/it]  2%|▏         | 20/1072 [11:24<10:34:00, 36.16s/it]                                                    {'loss': 2.6502, 'learning_rate': 4.345879896760937e-06, 'epoch': 0.04}  2%|▏         | 20/1072 [11:24<10:34:00, 36.16s/it]  2%|▏         | 21/1072 [12:02<10:39:46, 36.52s/it]  2%|▏         | 22/1072 [12:32<10:09:23, 34.82s/it]  2%|▏         | 23/1072 [13:09<10:15:24, 35.20s/it]  2%|▏         | 24/1072 [13:45<10:19:18, 35.46s/it]  2%|▏         | 25/1072 [14:21<10:22:03, 35.65s/it]  2%|▏         | 26/1072 [14:56<10:22:14, 35.69s/it]  3%|▎         | 27/1072 [15:32<10:23:10, 35.78s/it]  3%|▎         | 28/1072 [16:09<10:26:01, 35.98s/it]  3%|▎         | 29/1072 [16:45<10:25:34, 35.99s/it]  3%|▎         | 30/1072 [17:21<10:25:48, 36.03s/it]                                                    {'loss': 2.3821, 'learning_rate': 5.557309567291557e-06, 'epoch': 0.06}  3%|▎         | 30/1072 [17:21<10:25:48, 36.03s/it]  3%|▎         | 31/1072 [17:57<10:25:29, 36.05s/it]  3%|▎         | 32/1072 [18:33<10:24:54, 36.05s/it]  3%|▎         | 33/1072 [19:09<10:24:26, 36.06s/it]  3%|▎         | 34/1072 [19:46<10:25:15, 36.14s/it]  3%|▎         | 35/1072 [20:21<10:23:00, 36.05s/it]  3%|▎         | 36/1072 [20:57<10:22:08, 36.03s/it]  3%|▎         | 37/1072 [21:34<10:23:49, 36.16s/it]  4%|▎         | 38/1072 [22:10<10:23:15, 36.17s/it]  4%|▎         | 39/1072 [22:46<10:22:30, 36.16s/it]  4%|▎         | 40/1072 [23:22<10:19:00, 35.99s/it]                                                    {'loss': 2.2915, 'learning_rate': 6.355406060132516e-06, 'epoch': 0.07}  4%|▎         | 40/1072 [23:22<10:19:00, 35.99s/it]  4%|▍         | 41/1072 [23:57<10:16:55, 35.90s/it]  4%|▍         | 42/1072 [24:33<10:16:04, 35.89s/it]  4%|▍         | 43/1072 [25:09<10:16:45, 35.96s/it]  4%|▍         | 44/1072 [25:45<10:15:47, 35.94s/it]  4%|▍         | 45/1072 [26:22<10:16:38, 36.03s/it]  4%|▍         | 46/1072 [26:58<10:16:27, 36.05s/it]  4%|▍         | 47/1072 [27:34<10:15:06, 36.01s/it]  4%|▍         | 48/1072 [28:10<10:16:56, 36.15s/it]  5%|▍         | 49/1072 [28:47<10:19:43, 36.35s/it]  5%|▍         | 50/1072 [29:24<10:21:11, 36.47s/it]                                                    {'loss': 2.2487, 'learning_rate': 6.914575690124303e-06, 'epoch': 0.09}  5%|▍         | 50/1072 [29:24<10:21:11, 36.47s/it]  5%|▍         | 51/1072 [30:00<10:18:10, 36.33s/it]  5%|▍         | 52/1072 [30:35<10:14:12, 36.13s/it]  5%|▍         | 53/1072 [31:12<10:15:42, 36.25s/it]  5%|▌         | 54/1072 [31:48<10:14:10, 36.20s/it]  5%|▌         | 55/1072 [32:24<10:13:28, 36.19s/it]  5%|▌         | 56/1072 [33:00<10:12:25, 36.17s/it]  5%|▌         | 57/1072 [33:36<10:10:26, 36.09s/it]  5%|▌         | 58/1072 [34:13<10:12:33, 36.25s/it]  6%|▌         | 59/1072 [34:49<10:12:00, 36.25s/it]  6%|▌         | 60/1072 [35:25<10:11:11, 36.24s/it]                                                    {'loss': 2.2372, 'learning_rate': 7.345389165780057e-06, 'epoch': 0.11}  6%|▌         | 60/1072 [35:25<10:11:11, 36.24s/it]  6%|▌         | 61/1072 [36:02<10:13:08, 36.39s/it]  6%|▌         | 62/1072 [36:38<10:13:09, 36.43s/it]  6%|▌         | 63/1072 [37:15<10:12:11, 36.40s/it]  6%|▌         | 64/1072 [37:51<10:08:46, 36.24s/it]  6%|▌         | 65/1072 [38:27<10:10:15, 36.36s/it]  6%|▌         | 66/1072 [39:04<10:09:25, 36.35s/it]  6%|▋         | 67/1072 [39:40<10:06:43, 36.22s/it]  6%|▋         | 68/1072 [40:15<10:04:24, 36.12s/it]  6%|▋         | 69/1072 [40:51<10:00:36, 35.93s/it]  7%|▋         | 70/1072 [41:26<9:57:57, 35.81s/it]                                                    {'loss': 2.1898, 'learning_rate': 7.69591015753426e-06, 'epoch': 0.13}  7%|▋         | 70/1072 [41:26<9:57:57, 35.81s/it]  7%|▋         | 71/1072 [42:02<9:54:07, 35.61s/it]  7%|▋         | 72/1072 [42:37<9:54:14, 35.65s/it]  7%|▋         | 73/1072 [43:14<9:57:26, 35.88s/it]  7%|▋         | 74/1072 [43:49<9:55:09, 35.78s/it]  7%|▋         | 75/1072 [44:25<9:54:02, 35.75s/it]  7%|▋         | 76/1072 [45:01<9:54:52, 35.84s/it]  7%|▋         | 77/1072 [45:37<9:56:05, 35.95s/it]  7%|▋         | 78/1072 [46:13<9:56:07, 35.98s/it]  7%|▋         | 79/1072 [46:49<9:56:01, 36.01s/it]  7%|▋         | 80/1072 [47:25<9:55:25, 36.01s/it]                                                   {'loss': 2.1977, 'learning_rate': 7.991417296612165e-06, 'epoch': 0.15}  7%|▋         | 80/1072 [47:25<9:55:25, 36.01s/it]  8%|▊         | 81/1072 [48:02<9:56:29, 36.11s/it]  8%|▊         | 82/1072 [48:38<9:58:50, 36.29s/it]  8%|▊         | 83/1072 [49:15<9:57:45, 36.26s/it]  8%|▊         | 84/1072 [49:52<10:00:19, 36.46s/it]  8%|▊         | 85/1072 [50:28<9:57:41, 36.33s/it]   8%|▊         | 86/1072 [51:04<9:55:18, 36.23s/it]  8%|▊         | 87/1072 [51:40<9:54:49, 36.23s/it]  8%|▊         | 88/1072 [52:16<9:54:29, 36.25s/it]  8%|▊         | 89/1072 [52:52<9:52:04, 36.14s/it]  8%|▊         | 90/1072 [53:28<9:51:59, 36.17s/it]                                                   {'loss': 2.1968, 'learning_rate': 8.246859427588061e-06, 'epoch': 0.17}  8%|▊         | 90/1072 [53:28<9:51:59, 36.17s/it]  8%|▊         | 91/1072 [54:05<9:52:55, 36.26s/it]  9%|▊         | 92/1072 [54:41<9:52:55, 36.30s/it]  9%|▊         | 93/1072 [55:18<9:52:46, 36.33s/it]  9%|▉         | 94/1072 [55:54<9:52:01, 36.32s/it]  9%|▉         | 95/1072 [56:30<9:51:33, 36.33s/it]  9%|▉         | 96/1072 [57:06<9:50:48, 36.32s/it]  9%|▉         | 97/1072 [57:43<9:50:56, 36.37s/it]  9%|▉         | 98/1072 [58:19<9:50:18, 36.36s/it]  9%|▉         | 99/1072 [58:55<9:48:24, 36.28s/it]  9%|▉         | 100/1072 [59:32<9:48:03, 36.30s/it]                                                    {'loss': 2.1913, 'learning_rate': 8.471814840824796e-06, 'epoch': 0.19}  9%|▉         | 100/1072 [59:32<9:48:03, 36.30s/it]/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.  warnings.warn(/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.  warnings.warn(/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.  warnings.warn(  9%|▉         | 101/1072 [1:01:01<14:06:04, 52.28s/it] 10%|▉         | 102/1072 [1:01:36<12:39:10, 46.96s/it] 10%|▉         | 103/1072 [1:02:11<11:39:27, 43.31s/it] 10%|▉         | 104/1072 [1:02:45<10:55:38, 40.64s/it] 10%|▉         | 105/1072 [1:03:20<10:27:02, 38.91s/it] 10%|▉         | 106/1072 [1:03:54<10:02:49, 37.44s/it] 10%|▉         | 107/1072 [1:04:28<9:46:02, 36.44s/it]  10%|█         | 108/1072 [1:05:02<9:33:07, 35.67s/it] 10%|█         | 109/1072 [1:05:36<9:23:38, 35.12s/it] 10%|█         | 110/1072 [1:06:10<9:19:29, 34.90s/it]                                                      {'loss': 2.1874, 'learning_rate': 8.672790873470093e-06, 'epoch': 0.21} 10%|█         | 110/1072 [1:06:10<9:19:29, 34.90s/it] 10%|█         | 111/1072 [1:06:45<9:17:10, 34.79s/it] 10%|█         | 112/1072 [1:07:19<9:14:04, 34.63s/it] 11%|█         | 113/1072 [1:07:54<9:15:16, 34.74s/it] 11%|█         | 114/1072 [1:08:29<9:14:11, 34.71s/it] 11%|█         | 115/1072 [1:09:03<9:13:48, 34.72s/it] 11%|█         | 116/1072 [1:09:38<9:12:59, 34.71s/it] 11%|█         | 117/1072 [1:10:13<9:12:12, 34.69s/it] 11%|█         | 118/1072 [1:10:47<9:12:19, 34.74s/it] 11%|█         | 119/1072 [1:11:23<9:13:37, 34.86s/it] 11%|█         | 120/1072 [1:11:57<9:13:14, 34.87s/it]                                                      {'loss': 2.1784, 'learning_rate': 8.854410858528194e-06, 'epoch': 0.22} 11%|█         | 120/1072 [1:11:57<9:13:14, 34.87s/it] 11%|█▏        | 121/1072 [1:12:32<9:12:33, 34.86s/it] 11%|█▏        | 122/1072 [1:13:07<9:12:46, 34.91s/it] 11%|█▏        | 123/1072 [1:13:42<9:11:37, 34.88s/it] 12%|█▏        | 124/1072 [1:14:17<9:11:32, 34.91s/it] 12%|█▏        | 125/1072 [1:14:52<9:11:14, 34.93s/it] 12%|█▏        | 126/1072 [1:15:27<9:11:17, 34.97s/it] 12%|█▏        | 127/1072 [1:16:02<9:10:02, 34.92s/it] 12%|█▏        | 128/1072 [1:16:37<9:09:10, 34.91s/it] 12%|█▏        | 129/1072 [1:17:12<9:07:57, 34.86s/it] 12%|█▏        | 130/1072 [1:17:46<9:06:36, 34.82s/it]                                                      {'loss': 2.1694, 'learning_rate': 9.020077814299048e-06, 'epoch': 0.24} 12%|█▏        | 130/1072 [1:17:46<9:06:36, 34.82s/it] 12%|█▏        | 131/1072 [1:18:21<9:06:50, 34.87s/it] 12%|█▏        | 132/1072 [1:18:56<9:06:15, 34.87s/it] 12%|█▏        | 133/1072 [1:19:31<9:03:33, 34.73s/it] 12%|█▎        | 134/1072 [1:20:06<9:03:55, 34.79s/it] 13%|█▎        | 135/1072 [1:20:40<9:02:23, 34.73s/it] 13%|█▎        | 136/1072 [1:21:14<8:59:24, 34.58s/it] 13%|█▎        | 137/1072 [1:21:49<9:01:25, 34.74s/it] 13%|█▎        | 138/1072 [1:22:24<9:00:14, 34.71s/it] 13%|█▎        | 139/1072 [1:22:59<9:00:10, 34.74s/it] 13%|█▎        | 140/1072 [1:23:34<8:59:13, 34.71s/it]                                                      {'loss': 2.1571, 'learning_rate': 9.172369392299995e-06, 'epoch': 0.26} 13%|█▎        | 140/1072 [1:23:34<8:59:13, 34.71s/it] 13%|█▎        | 141/1072 [1:24:09<9:01:28, 34.90s/it] 13%|█▎        | 142/1072 [1:24:44<9:01:29, 34.94s/it] 13%|█▎        | 143/1072 [1:25:19<9:01:46, 34.99s/it] 13%|█▎        | 144/1072 [1:25:55<9:03:28, 35.14s/it] 14%|█▎        | 145/1072 [1:26:29<8:59:52, 34.94s/it] 14%|█▎        | 146/1072 [1:27:04<9:00:37, 35.03s/it] 14%|█▎        | 147/1072 [1:27:39<8:56:33, 34.80s/it] 14%|█▍        | 148/1072 [1:28:14<8:58:06, 34.94s/it] 14%|█▍        | 149/1072 [1:28:49<8:56:50, 34.90s/it] 14%|█▍        | 150/1072 [1:29:23<8:53:48, 34.74s/it]                                                      {'loss': 2.1394, 'learning_rate': 9.313284938885426e-06, 'epoch': 0.28} 14%|█▍        | 150/1072 [1:29:23<8:53:48, 34.74s/it] 14%|█▍        | 151/1072 [1:29:57<8:52:01, 34.66s/it] 14%|█▍        | 152/1072 [1:30:32<8:50:53, 34.62s/it] 14%|█▍        | 153/1072 [1:31:07<8:52:00, 34.73s/it] 14%|█▍        | 154/1072 [1:31:42<8:52:56, 34.83s/it] 14%|█▍        | 155/1072 [1:32:17<8:54:38, 34.98s/it] 15%|█▍        | 156/1072 [1:32:52<8:52:49, 34.90s/it] 15%|█▍        | 157/1072 [1:33:27<8:52:32, 34.92s/it] 15%|█▍        | 158/1072 [1:34:02<8:52:56, 34.98s/it] 15%|█▍        | 159/1072 [1:34:37<8:50:56, 34.89s/it] 15%|█▍        | 160/1072 [1:35:13<8:54:27, 35.16s/it]                                                      {'loss': 2.1446, 'learning_rate': 9.44440651580982e-06, 'epoch': 0.3} 15%|█▍        | 160/1072 [1:35:13<8:54:27, 35.16s/it] 15%|█▌        | 161/1072 [1:35:48<8:55:50, 35.29s/it] 15%|█▌        | 162/1072 [1:36:23<8:53:38, 35.19s/it] 15%|█▌        | 163/1072 [1:36:59<8:54:27, 35.28s/it] 15%|█▌        | 164/1072 [1:37:34<8:53:15, 35.24s/it] 15%|█▌        | 165/1072 [1:38:10<8:55:56, 35.45s/it] 15%|█▌        | 166/1072 [1:38:46<8:58:05, 35.64s/it] 16%|█▌        | 167/1072 [1:39:22<9:01:07, 35.88s/it] 16%|█▌        | 168/1072 [1:39:59<9:02:37, 36.01s/it] 16%|█▌        | 169/1072 [1:40:34<8:58:43, 35.80s/it] 16%|█▌        | 170/1072 [1:41:10<9:00:11, 35.93s/it]                                                      {'loss': 2.1443, 'learning_rate': 9.567007507371588e-06, 'epoch': 0.32} 16%|█▌        | 170/1072 [1:41:10<9:00:11, 35.93s/it] 16%|█▌        | 171/1072 [1:41:46<9:01:10, 36.04s/it] 16%|█▌        | 172/1072 [1:42:23<9:01:25, 36.10s/it] 16%|█▌        | 173/1072 [1:42:58<8:59:28, 36.01s/it] 16%|█▌        | 174/1072 [1:43:35<9:00:01, 36.08s/it] 16%|█▋        | 175/1072 [1:44:11<8:59:53, 36.11s/it] 16%|█▋        | 176/1072 [1:44:47<8:59:30, 36.13s/it] 17%|█▋        | 177/1072 [1:45:23<8:57:05, 36.01s/it] 17%|█▋        | 178/1072 [1:45:58<8:51:55, 35.70s/it] 17%|█▋        | 179/1072 [1:46:34<8:52:28, 35.78s/it] 17%|█▋        | 180/1072 [1:47:10<8:53:00, 35.85s/it]                                                      {'loss': 2.1406, 'learning_rate': 9.682128041841535e-06, 'epoch': 0.34} 17%|█▋        | 180/1072 [1:47:10<8:53:00, 35.85s/it] 17%|█▋        | 181/1072 [1:47:46<8:54:01, 35.96s/it] 17%|█▋        | 182/1072 [1:48:22<8:51:55, 35.86s/it] 17%|█▋        | 183/1072 [1:48:57<8:48:11, 35.65s/it] 17%|█▋        | 184/1072 [1:49:32<8:45:28, 35.50s/it] 17%|█▋        | 185/1072 [1:50:07<8:44:04, 35.45s/it] 17%|█▋        | 186/1072 [1:50:42<8:42:16, 35.37s/it] 17%|█▋        | 187/1072 [1:51:17<8:40:19, 35.28s/it] 18%|█▊        | 188/1072 [1:51:53<8:39:37, 35.27s/it] 18%|█▊        | 189/1072 [1:52:27<8:36:29, 35.10s/it] 18%|█▊        | 190/1072 [1:53:03<8:36:52, 35.16s/it]                                                      {'loss': 2.1422, 'learning_rate': 9.79062869769246e-06, 'epoch': 0.35} 18%|█▊        | 190/1072 [1:53:03<8:36:52, 35.16s/it] 18%|█▊        | 191/1072 [1:53:38<8:38:20, 35.30s/it] 18%|█▊        | 192/1072 [1:54:14<8:38:32, 35.35s/it] 18%|█▊        | 193/1072 [1:54:49<8:36:38, 35.27s/it] 18%|█▊        | 194/1072 [1:55:24<8:35:44, 35.24s/it] 18%|█▊        | 195/1072 [1:56:00<8:37:34, 35.41s/it] 18%|█▊        | 196/1072 [1:56:35<8:36:25, 35.37s/it] 18%|█▊        | 197/1072 [1:57:11<8:36:39, 35.43s/it] 18%|█▊        | 198/1072 [1:57:46<8:37:01, 35.49s/it] 19%|█▊        | 199/1072 [1:58:22<8:35:40, 35.44s/it] 19%|█▊        | 200/1072 [1:58:57<8:32:47, 35.28s/it]                                                      {'loss': 2.1328, 'learning_rate': 9.893229590500635e-06, 'epoch': 0.37} 19%|█▊        | 200/1072 [1:58:57<8:32:47, 35.28s/it] 19%|█▉        | 201/1072 [2:00:25<12:21:40, 51.09s/it] 19%|█▉        | 202/1072 [2:00:59<11:07:38, 46.04s/it] 19%|█▉        | 203/1072 [2:01:33<10:16:20, 42.55s/it] 19%|█▉        | 204/1072 [2:02:08<9:40:59, 40.16s/it]  19%|█▉        | 205/1072 [2:02:42<9:15:48, 38.46s/it] 19%|█▉        | 206/1072 [2:03:17<8:56:49, 37.19s/it] 19%|█▉        | 207/1072 [2:03:51<8:42:50, 36.27s/it] 19%|█▉        | 208/1072 [2:04:25<8:32:10, 35.57s/it] 19%|█▉        | 209/1072 [2:04:58<8:23:07, 34.98s/it] 20%|█▉        | 210/1072 [2:05:32<8:17:39, 34.64s/it]                                                      {'loss': 2.1303, 'learning_rate': 9.990539370375978e-06, 'epoch': 0.39} 20%|█▉        | 210/1072 [2:05:32<8:17:39, 34.64s/it] 20%|█▉        | 211/1072 [2:06:06<8:15:25, 34.52s/it] 20%|█▉        | 212/1072 [2:06:41<8:13:54, 34.46s/it] 20%|█▉        | 213/1072 [2:07:15<8:13:58, 34.50s/it] 20%|█▉        | 214/1072 [2:07:50<8:13:31, 34.51s/it] 20%|██        | 215/1072 [2:08:24<8:10:07, 34.31s/it] 20%|██        | 216/1072 [2:08:59<8:12:34, 34.53s/it] 20%|██        | 217/1072 [2:09:32<8:09:00, 34.32s/it] 20%|██        | 218/1072 [2:10:07<8:07:52, 34.28s/it] 20%|██        | 219/1072 [2:10:41<8:06:25, 34.21s/it] 21%|██        | 220/1072 [2:11:16<8:08:28, 34.40s/it]                                                      {'loss': 2.1223, 'learning_rate': 1e-05, 'epoch': 0.41} 21%|██        | 220/1072 [2:11:16<8:08:28, 34.40s/it] 21%|██        | 221/1072 [2:11:51<8:10:29, 34.58s/it] 21%|██        | 222/1072 [2:12:25<8:09:54, 34.58s/it] 21%|██        | 223/1072 [2:12:59<8:07:13, 34.43s/it] 21%|██        | 224/1072 [2:13:34<8:08:42, 34.58s/it] 21%|██        | 225/1072 [2:14:09<8:08:55, 34.63s/it] 21%|██        | 226/1072 [2:14:44<8:08:31, 34.65s/it] 21%|██        | 227/1072 [2:15:18<8:06:45, 34.56s/it] 21%|██▏       | 228/1072 [2:15:53<8:06:12, 34.56s/it] 21%|██▏       | 229/1072 [2:16:27<8:04:35, 34.49s/it] 21%|██▏       | 230/1072 [2:17:01<8:03:18, 34.44s/it]                                                      {'loss': 2.1015, 'learning_rate': 1e-05, 'epoch': 0.43} 21%|██▏       | 230/1072 [2:17:01<8:03:18, 34.44s/it] 22%|██▏       | 231/1072 [2:17:36<8:03:27, 34.49s/it] 22%|██▏       | 232/1072 [2:18:11<8:05:51, 34.70s/it] 22%|██▏       | 233/1072 [2:18:46<8:05:24, 34.71s/it] 22%|██▏       | 234/1072 [2:19:20<8:03:42, 34.63s/it] 22%|██▏       | 235/1072 [2:19:55<8:02:39, 34.60s/it] 22%|██▏       | 236/1072 [2:20:29<8:01:07, 34.53s/it] 22%|██▏       | 237/1072 [2:21:03<7:59:10, 34.43s/it] 22%|██▏       | 238/1072 [2:21:38<8:01:01, 34.61s/it] 22%|██▏       | 239/1072 [2:22:14<8:04:33, 34.90s/it] 22%|██▏       | 240/1072 [2:22:48<8:02:17, 34.78s/it]                                                      {'loss': 2.1099, 'learning_rate': 1e-05, 'epoch': 0.45} 22%|██▏       | 240/1072 [2:22:48<8:02:17, 34.78s/it] 22%|██▏       | 241/1072 [2:23:23<8:00:14, 34.67s/it] 23%|██▎       | 242/1072 [2:23:57<7:58:52, 34.62s/it] 23%|██▎       | 243/1072 [2:24:32<7:57:50, 34.58s/it] 23%|██▎       | 244/1072 [2:25:06<7:56:17, 34.51s/it] 23%|██▎       | 245/1072 [2:25:41<7:57:01, 34.61s/it] 23%|██▎       | 246/1072 [2:26:16<7:57:29, 34.68s/it] 23%|██▎       | 247/1072 [2:26:50<7:56:47, 34.68s/it] 23%|██▎       | 248/1072 [2:27:25<7:56:33, 34.70s/it] 23%|██▎       | 249/1072 [2:28:00<7:55:20, 34.65s/it] 23%|██▎       | 250/1072 [2:28:35<7:57:03, 34.82s/it]                                                      {'loss': 2.1096, 'learning_rate': 1e-05, 'epoch': 0.47} 23%|██▎       | 250/1072 [2:28:35<7:57:03, 34.82s/it] 23%|██▎       | 251/1072 [2:29:10<7:56:35, 34.83s/it] 24%|██▎       | 252/1072 [2:29:45<7:55:34, 34.80s/it] 24%|██▎       | 253/1072 [2:30:19<7:54:03, 34.73s/it] 24%|██▎       | 254/1072 [2:30:54<7:53:00, 34.69s/it] 24%|██▍       | 255/1072 [2:31:28<7:52:23, 34.69s/it] 24%|██▍       | 256/1072 [2:32:04<7:53:54, 34.85s/it] 24%|██▍       | 257/1072 [2:32:38<7:53:17, 34.84s/it] 24%|██▍       | 258/1072 [2:33:13<7:51:48, 34.78s/it] 24%|██▍       | 259/1072 [2:33:48<7:52:42, 34.89s/it] 24%|██▍       | 260/1072 [2:34:23<7:51:56, 34.87s/it]                                                      {'loss': 2.1068, 'learning_rate': 1e-05, 'epoch': 0.48} 24%|██▍       | 260/1072 [2:34:23<7:51:56, 34.87s/it] 24%|██▍       | 261/1072 [2:34:58<7:50:52, 34.84s/it] 24%|██▍       | 262/1072 [2:35:34<7:54:13, 35.13s/it] 25%|██▍       | 263/1072 [2:36:09<7:54:54, 35.22s/it] 25%|██▍       | 264/1072 [2:36:44<7:54:26, 35.23s/it] 25%|██▍       | 265/1072 [2:37:20<7:54:52, 35.31s/it] 25%|██▍       | 266/1072 [2:37:55<7:55:10, 35.37s/it] 25%|██▍       | 267/1072 [2:38:31<7:55:19, 35.43s/it] 25%|██▌       | 268/1072 [2:39:06<7:55:00, 35.45s/it] 25%|██▌       | 269/1072 [2:39:42<7:54:21, 35.44s/it] 25%|██▌       | 270/1072 [2:40:18<7:58:12, 35.78s/it]                                                      {'loss': 2.1039, 'learning_rate': 1e-05, 'epoch': 0.5} 25%|██▌       | 270/1072 [2:40:18<7:58:12, 35.78s/it] 25%|██▌       | 271/1072 [2:40:54<7:58:05, 35.81s/it] 25%|██▌       | 272/1072 [2:41:30<7:56:10, 35.71s/it] 25%|██▌       | 273/1072 [2:42:05<7:54:08, 35.61s/it] 26%|██▌       | 274/1072 [2:42:41<7:54:26, 35.67s/it] 26%|██▌       | 275/1072 [2:43:16<7:51:39, 35.51s/it] 26%|██▌       | 276/1072 [2:43:52<7:51:19, 35.53s/it] 26%|██▌       | 277/1072 [2:44:27<7:48:24, 35.35s/it] 26%|██▌       | 278/1072 [2:45:02<7:49:40, 35.49s/it] 26%|██▌       | 279/1072 [2:45:38<7:47:54, 35.40s/it] 26%|██▌       | 280/1072 [2:46:14<7:49:26, 35.56s/it]                                                      {'loss': 2.1032, 'learning_rate': 1e-05, 'epoch': 0.52} 26%|██▌       | 280/1072 [2:46:14<7:49:26, 35.56s/it] 26%|██▌       | 281/1072 [2:46:49<7:48:36, 35.55s/it] 26%|██▋       | 282/1072 [2:47:25<7:48:01, 35.55s/it] 26%|██▋       | 283/1072 [2:48:00<7:45:11, 35.38s/it] 26%|██▋       | 284/1072 [2:48:35<7:44:28, 35.37s/it] 27%|██▋       | 285/1072 [2:49:11<7:48:17, 35.70s/it] 27%|██▋       | 286/1072 [2:49:47<7:47:11, 35.66s/it] 27%|██▋       | 287/1072 [2:50:22<7:44:26, 35.50s/it] 27%|██▋       | 288/1072 [2:50:57<7:41:21, 35.31s/it] 27%|██▋       | 289/1072 [2:51:33<7:43:28, 35.51s/it] 27%|██▋       | 290/1072 [2:52:08<7:42:47, 35.51s/it]                                                      {'loss': 2.1064, 'learning_rate': 1e-05, 'epoch': 0.54} 27%|██▋       | 290/1072 [2:52:08<7:42:47, 35.51s/it] 27%|██▋       | 291/1072 [2:52:43<7:40:26, 35.37s/it] 27%|██▋       | 292/1072 [2:53:19<7:40:35, 35.43s/it] 27%|██▋       | 293/1072 [2:53:54<7:38:14, 35.29s/it] 27%|██▋       | 294/1072 [2:54:29<7:35:46, 35.15s/it] 28%|██▊       | 295/1072 [2:55:04<7:35:21, 35.16s/it] 28%|██▊       | 296/1072 [2:55:39<7:36:03, 35.26s/it] 28%|██▊       | 297/1072 [2:56:15<7:37:11, 35.40s/it] 28%|██▊       | 298/1072 [2:56:51<7:37:18, 35.45s/it] 28%|██▊       | 299/1072 [2:57:26<7:36:10, 35.41s/it] 28%|██▊       | 300/1072 [2:58:02<7:36:46, 35.50s/it]                                                      {'loss': 2.1005, 'learning_rate': 1e-05, 'epoch': 0.56} 28%|██▊       | 300/1072 [2:58:02<7:36:46, 35.50s/it] 28%|██▊       | 301/1072 [2:59:34<11:14:20, 52.48s/it] 28%|██▊       | 302/1072 [3:00:09<10:05:46, 47.20s/it] 28%|██▊       | 303/1072 [3:00:43<9:14:46, 43.29s/it]  28%|██▊       | 304/1072 [3:01:17<8:39:09, 40.56s/it] 28%|██▊       | 305/1072 [3:01:51<8:14:39, 38.70s/it] 29%|██▊       | 306/1072 [3:02:26<7:57:45, 37.42s/it] 29%|██▊       | 307/1072 [3:03:00<7:45:05, 36.48s/it] 29%|██▊       | 308/1072 [3:03:34<7:33:19, 35.60s/it] 29%|██▉       | 309/1072 [3:04:08<7:27:53, 35.22s/it] 29%|██▉       | 310/1072 [3:04:42<7:23:27, 34.92s/it]                                                      {'loss': 2.1286, 'learning_rate': 1e-05, 'epoch': 0.58} 29%|██▉       | 310/1072 [3:04:42<7:23:27, 34.92s/it] 29%|██▉       | 311/1072 [3:05:17<7:21:00, 34.77s/it] 29%|██▉       | 312/1072 [3:05:51<7:18:33, 34.62s/it] 29%|██▉       | 313/1072 [3:06:25<7:15:08, 34.40s/it] 29%|██▉       | 314/1072 [3:06:59<7:14:46, 34.41s/it] 29%|██▉       | 315/1072 [3:07:33<7:13:03, 34.32s/it] 29%|██▉       | 316/1072 [3:08:09<7:16:54, 34.68s/it] 30%|██▉       | 317/1072 [3:08:44<7:18:25, 34.84s/it] 30%|██▉       | 318/1072 [3:09:19<7:16:46, 34.76s/it] 30%|██▉       | 319/1072 [3:09:53<7:15:26, 34.70s/it] 30%|██▉       | 320/1072 [3:10:28<7:15:17, 34.73s/it]                                                      {'loss': 2.1242, 'learning_rate': 1e-05, 'epoch': 0.6} 30%|██▉       | 320/1072 [3:10:28<7:15:17, 34.73s/it] 30%|██▉       | 321/1072 [3:11:03<7:14:19, 34.70s/it] 30%|███       | 322/1072 [3:11:37<7:13:29, 34.68s/it] 30%|███       | 323/1072 [3:12:12<7:14:06, 34.78s/it] 30%|███       | 324/1072 [3:12:47<7:11:30, 34.61s/it] 30%|███       | 325/1072 [3:13:21<7:11:55, 34.69s/it] 30%|███       | 326/1072 [3:13:56<7:10:58, 34.66s/it] 31%|███       | 327/1072 [3:14:31<7:10:37, 34.68s/it] 31%|███       | 328/1072 [3:15:06<7:10:45, 34.74s/it] 31%|███       | 329/1072 [3:15:41<7:10:38, 34.78s/it] 31%|███       | 330/1072 [3:16:16<7:10:56, 34.85s/it]                                                      {'loss': 2.0973, 'learning_rate': 1e-05, 'epoch': 0.62} 31%|███       | 330/1072 [3:16:16<7:10:56, 34.85s/it] 31%|███       | 331/1072 [3:16:49<7:05:54, 34.49s/it] 31%|███       | 332/1072 [3:17:24<7:06:54, 34.61s/it] 31%|███       | 333/1072 [3:17:58<7:04:49, 34.49s/it] 31%|███       | 334/1072 [3:18:33<7:05:09, 34.57s/it] 31%|███▏      | 335/1072 [3:19:08<7:06:56, 34.76s/it] 31%|███▏      | 336/1072 [3:19:43<7:04:47, 34.63s/it] 31%|███▏      | 337/1072 [3:20:17<7:05:07, 34.70s/it] 32%|███▏      | 338/1072 [3:20:52<7:05:22, 34.77s/it] 32%|███▏      | 339/1072 [3:21:26<7:02:00, 34.54s/it] 32%|███▏      | 340/1072 [3:22:01<7:01:46, 34.57s/it]                                                      {'loss': 2.0943, 'learning_rate': 1e-05, 'epoch': 0.63} 32%|███▏      | 340/1072 [3:22:01<7:01:46, 34.57s/it] 32%|███▏      | 341/1072 [3:22:35<7:00:33, 34.52s/it] 32%|███▏      | 342/1072 [3:23:10<6:58:32, 34.40s/it] 32%|███▏      | 343/1072 [3:23:44<6:57:47, 34.39s/it] 32%|███▏      | 344/1072 [3:24:19<6:59:25, 34.57s/it] 32%|███▏      | 345/1072 [3:24:54<7:01:24, 34.78s/it] 32%|███▏      | 346/1072 [3:25:29<7:02:09, 34.89s/it] 32%|███▏      | 347/1072 [3:26:04<7:02:30, 34.97s/it] 32%|███▏      | 348/1072 [3:26:40<7:02:34, 35.02s/it] 33%|███▎      | 349/1072 [3:27:15<7:02:52, 35.09s/it] 33%|███▎      | 350/1072 [3:27:50<7:01:44, 35.05s/it]                                                      {'loss': 2.1017, 'learning_rate': 1e-05, 'epoch': 0.65} 33%|███▎      | 350/1072 [3:27:50<7:01:44, 35.05s/it] 33%|███▎      | 351/1072 [3:28:25<7:01:40, 35.09s/it] 33%|███▎      | 352/1072 [3:29:00<7:01:24, 35.12s/it] 33%|███▎      | 353/1072 [3:29:35<6:59:50, 35.04s/it] 33%|███▎      | 354/1072 [3:30:10<6:59:13, 35.03s/it] 33%|███▎      | 355/1072 [3:30:45<6:59:26, 35.10s/it] 33%|███▎      | 356/1072 [3:31:20<6:59:01, 35.11s/it] 33%|███▎      | 357/1072 [3:31:56<7:01:00, 35.33s/it] 33%|███▎      | 358/1072 [3:32:32<7:02:28, 35.50s/it] 33%|███▎      | 359/1072 [3:33:07<6:59:25, 35.30s/it] 34%|███▎      | 360/1072 [3:33:43<6:59:50, 35.38s/it]                                                      {'loss': 2.0889, 'learning_rate': 1e-05, 'epoch': 0.67} 34%|███▎      | 360/1072 [3:33:43<6:59:50, 35.38s/it] 34%|███▎      | 361/1072 [3:34:18<7:00:29, 35.48s/it] 34%|███▍      | 362/1072 [3:34:54<6:58:49, 35.39s/it] 34%|███▍      | 363/1072 [3:35:29<6:57:42, 35.35s/it] 34%|███▍      | 364/1072 [3:36:05<6:59:09, 35.52s/it] 34%|███▍      | 365/1072 [3:36:41<7:01:24, 35.76s/it] 34%|███▍      | 366/1072 [3:37:17<7:02:57, 35.95s/it] 34%|███▍      | 367/1072 [3:37:53<7:01:04, 35.84s/it] 34%|███▍      | 368/1072 [3:38:28<6:59:24, 35.74s/it] 34%|███▍      | 369/1072 [3:39:05<6:59:47, 35.83s/it] 35%|███▍      | 370/1072 [3:39:40<6:58:13, 35.75s/it]                                                      {'loss': 2.1028, 'learning_rate': 1e-05, 'epoch': 0.69} 35%|███▍      | 370/1072 [3:39:40<6:58:13, 35.75s/it] 35%|███▍      | 371/1072 [3:40:15<6:55:39, 35.58s/it] 35%|███▍      | 372/1072 [3:40:51<6:55:28, 35.61s/it] 35%|███▍      | 373/1072 [3:41:27<6:54:51, 35.61s/it] 35%|███▍      | 374/1072 [3:42:03<6:57:34, 35.89s/it] 35%|███▍      | 375/1072 [3:42:40<6:58:58, 36.07s/it] 35%|███▌      | 376/1072 [3:43:15<6:57:33, 36.00s/it] 35%|███▌      | 377/1072 [3:43:51<6:56:13, 35.93s/it] 35%|███▌      | 378/1072 [3:44:27<6:55:18, 35.91s/it] 35%|███▌      | 379/1072 [3:45:03<6:54:43, 35.91s/it] 35%|███▌      | 380/1072 [3:45:38<6:50:33, 35.60s/it]                                                      {'loss': 2.0805, 'learning_rate': 1e-05, 'epoch': 0.71} 35%|███▌      | 380/1072 [3:45:38<6:50:33, 35.60s/it] 36%|███▌      | 381/1072 [3:46:13<6:49:17, 35.54s/it] 36%|███▌      | 382/1072 [3:46:49<6:48:32, 35.53s/it] 36%|███▌      | 383/1072 [3:47:24<6:47:11, 35.46s/it] 36%|███▌      | 384/1072 [3:47:59<6:46:37, 35.46s/it] 36%|███▌      | 385/1072 [3:48:34<6:43:51, 35.27s/it] 36%|███▌      | 386/1072 [3:49:09<6:42:16, 35.18s/it] 36%|███▌      | 387/1072 [3:49:44<6:40:25, 35.07s/it] 36%|███▌      | 388/1072 [3:50:19<6:38:36, 34.96s/it] 36%|███▋      | 389/1072 [3:50:53<6:36:38, 34.84s/it] 36%|███▋      | 390/1072 [3:51:28<6:36:22, 34.87s/it]                                                      {'loss': 2.0962, 'learning_rate': 1e-05, 'epoch': 0.73} 36%|███▋      | 390/1072 [3:51:28<6:36:22, 34.87s/it] 36%|███▋      | 391/1072 [3:52:03<6:34:57, 34.80s/it] 37%|███▋      | 392/1072 [3:52:38<6:34:10, 34.78s/it] 37%|███▋      | 393/1072 [3:53:12<6:32:36, 34.69s/it] 37%|███▋      | 394/1072 [3:53:47<6:33:13, 34.80s/it] 37%|███▋      | 395/1072 [3:54:23<6:35:52, 35.09s/it] 37%|███▋      | 396/1072 [3:54:58<6:35:46, 35.13s/it] 37%|███▋      | 397/1072 [3:55:34<6:36:25, 35.24s/it] 37%|███▋      | 398/1072 [3:56:09<6:37:18, 35.37s/it] 37%|███▋      | 399/1072 [3:56:44<6:35:39, 35.27s/it] 37%|███▋      | 400/1072 [3:57:19<6:34:12, 35.20s/it]                                                      {'loss': 2.0916, 'learning_rate': 1e-05, 'epoch': 0.75} 37%|███▋      | 400/1072 [3:57:19<6:34:12, 35.20s/it] 37%|███▋      | 401/1072 [3:58:50<9:40:28, 51.91s/it] 38%|███▊      | 402/1072 [3:59:25<8:41:10, 46.67s/it] 38%|███▊      | 403/1072 [3:59:59<8:00:23, 43.08s/it] 38%|███▊      | 404/1072 [4:00:34<7:30:19, 40.45s/it] 38%|███▊      | 405/1072 [4:01:08<7:08:28, 38.54s/it] 38%|███▊      | 406/1072 [4:01:42<6:54:32, 37.35s/it] 38%|███▊      | 407/1072 [4:02:17<6:45:18, 36.57s/it] 38%|███▊      | 408/1072 [4:02:51<6:36:08, 35.80s/it] 38%|███▊      | 409/1072 [4:03:26<6:31:20, 35.42s/it] 38%|███▊      | 410/1072 [4:04:00<6:27:18, 35.10s/it]                                                      {'loss': 2.0845, 'learning_rate': 1e-05, 'epoch': 0.76} 38%|███▊      | 410/1072 [4:04:00<6:27:18, 35.10s/it] 38%|███▊      | 411/1072 [4:04:34<6:23:29, 34.81s/it] 38%|███▊      | 412/1072 [4:05:09<6:21:21, 34.67s/it] 39%|███▊      | 413/1072 [4:05:43<6:20:44, 34.67s/it] 39%|███▊      | 414/1072 [4:06:18<6:19:54, 34.64s/it] 39%|███▊      | 415/1072 [4:06:53<6:19:37, 34.67s/it] 39%|███▉      | 416/1072 [4:07:27<6:18:20, 34.60s/it] 39%|███▉      | 417/1072 [4:08:01<6:16:13, 34.46s/it] 39%|███▉      | 418/1072 [4:08:36<6:16:05, 34.50s/it] 39%|███▉      | 419/1072 [4:09:10<6:15:07, 34.47s/it] 39%|███▉      | 420/1072 [4:09:45<6:14:45, 34.49s/it]                                                      {'loss': 2.0911, 'learning_rate': 1e-05, 'epoch': 0.78} 39%|███▉      | 420/1072 [4:09:45<6:14:45, 34.49s/it] 39%|███▉      | 421/1072 [4:10:19<6:14:15, 34.49s/it] 39%|███▉      | 422/1072 [4:10:54<6:15:28, 34.66s/it] 39%|███▉      | 423/1072 [4:11:29<6:15:28, 34.71s/it] 40%|███▉      | 424/1072 [4:12:04<6:15:43, 34.79s/it] 40%|███▉      | 425/1072 [4:12:39<6:16:11, 34.89s/it] 40%|███▉      | 426/1072 [4:13:14<6:15:32, 34.88s/it] 40%|███▉      | 427/1072 [4:13:49<6:16:14, 35.00s/it] 40%|███▉      | 428/1072 [4:14:25<6:16:28, 35.08s/it] 40%|████      | 429/1072 [4:15:00<6:17:08, 35.19s/it] 40%|████      | 430/1072 [4:15:35<6:15:34, 35.10s/it]                                                      {'loss': 2.08, 'learning_rate': 1e-05, 'epoch': 0.8} 40%|████      | 430/1072 [4:15:35<6:15:34, 35.10s/it] 40%|████      | 431/1072 [4:16:10<6:15:21, 35.13s/it] 40%|████      | 432/1072 [4:16:45<6:12:36, 34.93s/it] 40%|████      | 433/1072 [4:17:19<6:11:25, 34.88s/it] 40%|████      | 434/1072 [4:17:54<6:10:31, 34.85s/it] 41%|████      | 435/1072 [4:18:29<6:08:56, 34.75s/it] 41%|████      | 436/1072 [4:19:04<6:09:14, 34.83s/it] 41%|████      | 437/1072 [4:19:39<6:10:08, 34.97s/it] 41%|████      | 438/1072 [4:20:14<6:10:31, 35.07s/it] 41%|████      | 439/1072 [4:20:48<6:07:04, 34.79s/it] 41%|████      | 440/1072 [4:21:23<6:06:38, 34.81s/it]                                                      {'loss': 2.092, 'learning_rate': 1e-05, 'epoch': 0.82} 41%|████      | 440/1072 [4:21:23<6:06:38, 34.81s/it] 41%|████      | 441/1072 [4:21:58<6:07:16, 34.92s/it] 41%|████      | 442/1072 [4:22:33<6:04:23, 34.70s/it] 41%|████▏     | 443/1072 [4:23:09<6:08:51, 35.19s/it] 41%|████▏     | 444/1072 [4:23:45<6:10:09, 35.37s/it] 42%|████▏     | 445/1072 [4:24:20<6:09:26, 35.35s/it] 42%|████▏     | 446/1072 [4:24:55<6:08:59, 35.37s/it] 42%|████▏     | 447/1072 [4:25:32<6:11:18, 35.65s/it] 42%|████▏     | 448/1072 [4:26:08<6:14:04, 35.97s/it] 42%|████▏     | 449/1072 [4:26:45<6:14:01, 36.02s/it] 42%|████▏     | 450/1072 [4:27:21<6:13:22, 36.02s/it]                                                      {'loss': 2.0945, 'learning_rate': 1e-05, 'epoch': 0.84} 42%|████▏     | 450/1072 [4:27:21<6:13:22, 36.02s/it] 42%|████▏     | 451/1072 [4:27:56<6:12:29, 35.99s/it] 42%|████▏     | 452/1072 [4:28:33<6:12:08, 36.01s/it] 42%|████▏     | 453/1072 [4:29:09<6:11:55, 36.05s/it] 42%|████▏     | 454/1072 [4:29:44<6:08:58, 35.82s/it] 42%|████▏     | 455/1072 [4:30:20<6:08:21, 35.82s/it] 43%|████▎     | 456/1072 [4:30:55<6:06:50, 35.73s/it] 43%|████▎     | 457/1072 [4:31:31<6:06:20, 35.74s/it] 43%|████▎     | 458/1072 [4:32:07<6:07:05, 35.87s/it] 43%|████▎     | 459/1072 [4:32:43<6:06:29, 35.87s/it] 43%|████▎     | 460/1072 [4:33:19<6:05:05, 35.79s/it]                                                      {'loss': 2.0654, 'learning_rate': 1e-05, 'epoch': 0.86} 43%|████▎     | 460/1072 [4:33:19<6:05:05, 35.79s/it] 43%|████▎     | 461/1072 [4:33:54<6:03:44, 35.72s/it] 43%|████▎     | 462/1072 [4:34:30<6:03:16, 35.73s/it] 43%|████▎     | 463/1072 [4:35:05<6:01:26, 35.61s/it] 43%|████▎     | 464/1072 [4:35:41<6:01:34, 35.68s/it] 43%|████▎     | 465/1072 [4:36:17<6:00:32, 35.64s/it] 43%|████▎     | 466/1072 [4:36:53<6:01:02, 35.75s/it] 44%|████▎     | 467/1072 [4:37:29<6:03:15, 36.02s/it] 44%|████▎     | 468/1072 [4:38:05<6:02:29, 36.01s/it] 44%|████▍     | 469/1072 [4:38:41<6:01:30, 35.97s/it] 44%|████▍     | 470/1072 [4:39:17<6:01:33, 36.04s/it]                                                      {'loss': 2.0812, 'learning_rate': 1e-05, 'epoch': 0.88} 44%|████▍     | 470/1072 [4:39:17<6:01:33, 36.04s/it] 44%|████▍     | 471/1072 [4:39:54<6:01:34, 36.10s/it] 44%|████▍     | 472/1072 [4:40:30<6:00:30, 36.05s/it] 44%|████▍     | 473/1072 [4:41:06<5:59:35, 36.02s/it] 44%|████▍     | 474/1072 [4:41:42<5:59:35, 36.08s/it] 44%|████▍     | 475/1072 [4:42:18<5:58:07, 35.99s/it] 44%|████▍     | 476/1072 [4:42:54<5:57:43, 36.01s/it] 44%|████▍     | 477/1072 [4:43:30<5:57:39, 36.07s/it] 45%|████▍     | 478/1072 [4:44:06<5:57:10, 36.08s/it] 45%|████▍     | 479/1072 [4:44:41<5:54:44, 35.89s/it] 45%|████▍     | 480/1072 [4:45:16<5:51:34, 35.63s/it]                                                      {'loss': 2.0634, 'learning_rate': 1e-05, 'epoch': 0.89} 45%|████▍     | 480/1072 [4:45:16<5:51:34, 35.63s/it] 45%|████▍     | 481/1072 [4:45:53<5:52:20, 35.77s/it] 45%|████▍     | 482/1072 [4:46:28<5:52:08, 35.81s/it] 45%|████▌     | 483/1072 [4:47:04<5:52:11, 35.88s/it] 45%|████▌     | 484/1072 [4:47:40<5:51:31, 35.87s/it] 45%|████▌     | 485/1072 [4:48:16<5:51:27, 35.92s/it] 45%|████▌     | 486/1072 [4:48:52<5:51:07, 35.95s/it] 45%|████▌     | 487/1072 [4:49:29<5:51:21, 36.04s/it] 46%|████▌     | 488/1072 [4:50:04<5:48:44, 35.83s/it] 46%|████▌     | 489/1072 [4:50:39<5:46:09, 35.63s/it] 46%|████▌     | 490/1072 [4:51:15<5:45:32, 35.62s/it]                                                      {'loss': 2.0596, 'learning_rate': 1e-05, 'epoch': 0.91} 46%|████▌     | 490/1072 [4:51:15<5:45:32, 35.62s/it] 46%|████▌     | 491/1072 [4:51:50<5:43:32, 35.48s/it] 46%|████▌     | 492/1072 [4:52:26<5:44:25, 35.63s/it] 46%|████▌     | 493/1072 [4:53:01<5:43:43, 35.62s/it] 46%|████▌     | 494/1072 [4:53:37<5:42:16, 35.53s/it] 46%|████▌     | 495/1072 [4:54:13<5:42:13, 35.59s/it] 46%|████▋     | 496/1072 [4:54:48<5:41:27, 35.57s/it] 46%|████▋     | 497/1072 [4:55:24<5:41:40, 35.65s/it] 46%|████▋     | 498/1072 [4:56:00<5:42:54, 35.84s/it] 47%|████▋     | 499/1072 [4:56:35<5:40:06, 35.61s/it] 47%|████▋     | 500/1072 [4:57:11<5:41:10, 35.79s/it]                                                      {'loss': 2.0508, 'learning_rate': 1e-05, 'epoch': 0.93} 47%|████▋     | 500/1072 [4:57:11<5:41:10, 35.79s/it] 47%|████▋     | 501/1072 [4:58:48<8:33:18, 53.94s/it] 47%|████▋     | 502/1072 [4:59:22<7:36:53, 48.09s/it] 47%|████▋     | 503/1072 [4:59:56<6:55:32, 43.82s/it] 47%|████▋     | 504/1072 [5:00:30<6:27:13, 40.90s/it] 47%|████▋     | 505/1072 [5:01:04<6:06:58, 38.83s/it] 47%|████▋     | 506/1072 [5:01:39<5:53:40, 37.49s/it] 47%|████▋     | 507/1072 [5:02:13<5:43:52, 36.52s/it] 47%|████▋     | 508/1072 [5:02:47<5:36:41, 35.82s/it] 47%|████▋     | 509/1072 [5:03:21<5:31:14, 35.30s/it] 48%|████▊     | 510/1072 [5:03:55<5:27:31, 34.97s/it]                                                      {'loss': 2.0717, 'learning_rate': 1e-05, 'epoch': 0.95} 48%|████▊     | 510/1072 [5:03:55<5:27:31, 34.97s/it] 48%|████▊     | 511/1072 [5:04:30<5:25:54, 34.86s/it] 48%|████▊     | 512/1072 [5:05:04<5:24:04, 34.72s/it] 48%|████▊     | 513/1072 [5:05:38<5:22:02, 34.57s/it] 48%|████▊     | 514/1072 [5:06:13<5:22:48, 34.71s/it] 48%|████▊     | 515/1072 [5:06:48<5:21:51, 34.67s/it] 48%|████▊     | 516/1072 [5:07:23<5:21:45, 34.72s/it] 48%|████▊     | 517/1072 [5:07:57<5:20:12, 34.62s/it] 48%|████▊     | 518/1072 [5:08:32<5:19:34, 34.61s/it] 48%|████▊     | 519/1072 [5:09:07<5:19:27, 34.66s/it] 49%|████▊     | 520/1072 [5:09:41<5:18:28, 34.62s/it]                                                      {'loss': 2.0872, 'learning_rate': 1e-05, 'epoch': 0.97} 49%|████▊     | 520/1072 [5:09:41<5:18:28, 34.62s/it] 49%|████▊     | 521/1072 [5:10:16<5:18:17, 34.66s/it] 49%|████▊     | 522/1072 [5:10:51<5:19:11, 34.82s/it] 49%|████▉     | 523/1072 [5:11:26<5:18:28, 34.81s/it] 49%|████▉     | 524/1072 [5:12:02<5:20:14, 35.06s/it] 49%|████▉     | 525/1072 [5:12:37<5:19:28, 35.04s/it] 49%|████▉     | 526/1072 [5:13:12<5:19:50, 35.15s/it] 49%|████▉     | 527/1072 [5:13:47<5:20:07, 35.24s/it] 49%|████▉     | 528/1072 [5:14:23<5:19:41, 35.26s/it] 49%|████▉     | 529/1072 [5:14:58<5:19:24, 35.29s/it] 49%|████▉     | 530/1072 [5:15:34<5:19:39, 35.39s/it]                                                      {'loss': 2.0708, 'learning_rate': 1e-05, 'epoch': 0.99} 49%|████▉     | 530/1072 [5:15:34<5:19:39, 35.39s/it] 50%|████▉     | 531/1072 [5:16:09<5:19:55, 35.48s/it] 50%|████▉     | 532/1072 [5:16:45<5:19:32, 35.50s/it] 50%|████▉     | 533/1072 [5:17:20<5:18:50, 35.49s/it] 50%|████▉     | 534/1072 [5:17:56<5:19:42, 35.66s/it] 50%|████▉     | 535/1072 [5:18:32<5:17:51, 35.51s/it] 50%|█████     | 536/1072 [5:19:08<5:19:35, 35.77s/it] 50%|█████     | 537/1072 [5:20:04<6:12:18, 41.75s/it] 50%|█████     | 538/1072 [5:20:41<5:59:14, 40.36s/it] 50%|█████     | 539/1072 [5:21:17<5:47:45, 39.15s/it] 50%|█████     | 540/1072 [5:21:53<5:38:31, 38.18s/it]                                                      {'loss': 1.9827, 'learning_rate': 1e-05, 'epoch': 1.01} 50%|█████     | 540/1072 [5:21:53<5:38:31, 38.18s/it] 50%|█████     | 541/1072 [5:22:28<5:29:32, 37.24s/it] 51%|█████     | 542/1072 [5:23:04<5:25:10, 36.81s/it] 51%|█████     | 543/1072 [5:23:39<5:18:58, 36.18s/it] 51%|█████     | 544/1072 [5:24:15<5:17:56, 36.13s/it] 51%|█████     | 545/1072 [5:24:51<5:17:02, 36.10s/it] 51%|█████     | 546/1072 [5:25:27<5:16:05, 36.06s/it] 51%|█████     | 547/1072 [5:26:03<5:15:11, 36.02s/it] 51%|█████     | 548/1072 [5:26:38<5:13:03, 35.85s/it] 51%|█████     | 549/1072 [5:27:14<5:12:55, 35.90s/it] 51%|█████▏    | 550/1072 [5:27:50<5:11:51, 35.85s/it]                                                      {'loss': 1.7781, 'learning_rate': 1e-05, 'epoch': 1.03} 51%|█████▏    | 550/1072 [5:27:50<5:11:51, 35.85s/it] 51%|█████▏    | 551/1072 [5:28:26<5:12:03, 35.94s/it] 51%|█████▏    | 552/1072 [5:29:02<5:11:13, 35.91s/it] 52%|█████▏    | 553/1072 [5:29:38<5:11:09, 35.97s/it] 52%|█████▏    | 554/1072 [5:30:14<5:11:17, 36.06s/it] 52%|█████▏    | 555/1072 [5:30:50<5:10:59, 36.09s/it] 52%|█████▏    | 556/1072 [5:31:26<5:09:46, 36.02s/it] 52%|█████▏    | 557/1072 [5:32:01<5:07:12, 35.79s/it] 52%|█████▏    | 558/1072 [5:32:37<5:05:22, 35.65s/it] 52%|█████▏    | 559/1072 [5:33:12<5:04:25, 35.61s/it] 52%|█████▏    | 560/1072 [5:33:48<5:03:15, 35.54s/it]                                                      {'loss': 1.7684, 'learning_rate': 1e-05, 'epoch': 1.04} 52%|█████▏    | 560/1072 [5:33:48<5:03:15, 35.54s/it] 52%|█████▏    | 561/1072 [5:34:24<5:04:17, 35.73s/it] 52%|█████▏    | 562/1072 [5:35:00<5:03:56, 35.76s/it] 53%|█████▎    | 563/1072 [5:35:35<5:03:34, 35.79s/it] 53%|█████▎    | 564/1072 [5:36:11<5:03:09, 35.81s/it] 53%|█████▎    | 565/1072 [5:36:47<5:02:45, 35.83s/it] 53%|█████▎    | 566/1072 [5:37:23<5:01:46, 35.78s/it] 53%|█████▎    | 567/1072 [5:37:59<5:00:58, 35.76s/it] 53%|█████▎    | 568/1072 [5:38:34<4:58:30, 35.54s/it] 53%|█████▎    | 569/1072 [5:39:09<4:57:23, 35.47s/it] 53%|█████▎    | 570/1072 [5:39:44<4:56:10, 35.40s/it]                                                      {'loss': 1.7805, 'learning_rate': 1e-05, 'epoch': 1.06} 53%|█████▎    | 570/1072 [5:39:44<4:56:10, 35.40s/it] 53%|█████▎    | 571/1072 [5:40:19<4:54:39, 35.29s/it] 53%|█████▎    | 572/1072 [5:40:55<4:56:03, 35.53s/it] 53%|█████▎    | 573/1072 [5:41:30<4:54:36, 35.42s/it] 54%|█████▎    | 574/1072 [5:42:06<4:54:37, 35.50s/it] 54%|█████▎    | 575/1072 [5:42:42<4:55:54, 35.72s/it] 54%|█████▎    | 576/1072 [5:43:19<4:57:08, 35.94s/it] 54%|█████▍    | 577/1072 [5:43:55<4:58:15, 36.15s/it] 54%|█████▍    | 578/1072 [5:44:32<4:57:29, 36.13s/it] 54%|█████▍    | 579/1072 [5:45:08<4:57:10, 36.17s/it] 54%|█████▍    | 580/1072 [5:45:43<4:54:38, 35.93s/it]                                                      {'loss': 1.7828, 'learning_rate': 1e-05, 'epoch': 1.08} 54%|█████▍    | 580/1072 [5:45:43<4:54:38, 35.93s/it] 54%|█████▍    | 581/1072 [5:46:19<4:53:02, 35.81s/it] 54%|█████▍    | 582/1072 [5:46:54<4:52:00, 35.76s/it] 54%|█████▍    | 583/1072 [5:47:30<4:51:11, 35.73s/it] 54%|█████▍    | 584/1072 [5:48:06<4:52:19, 35.94s/it] 55%|█████▍    | 585/1072 [5:48:43<4:52:12, 36.00s/it] 55%|█████▍    | 586/1072 [5:49:18<4:50:58, 35.92s/it] 55%|█████▍    | 587/1072 [5:49:54<4:50:39, 35.96s/it] 55%|█████▍    | 588/1072 [5:50:31<4:50:34, 36.02s/it] 55%|█████▍    | 589/1072 [5:51:07<4:50:01, 36.03s/it] 55%|█████▌    | 590/1072 [5:51:42<4:48:48, 35.95s/it]                                                      {'loss': 1.7874, 'learning_rate': 1e-05, 'epoch': 1.1} 55%|█████▌    | 590/1072 [5:51:42<4:48:48, 35.95s/it] 55%|█████▌    | 591/1072 [5:52:19<4:49:16, 36.08s/it] 55%|█████▌    | 592/1072 [5:52:55<4:48:39, 36.08s/it] 55%|█████▌    | 593/1072 [5:53:30<4:46:47, 35.92s/it] 55%|█████▌    | 594/1072 [5:54:06<4:45:00, 35.78s/it] 56%|█████▌    | 595/1072 [5:54:41<4:43:09, 35.62s/it] 56%|█████▌    | 596/1072 [5:55:16<4:41:49, 35.52s/it] 56%|█████▌    | 597/1072 [5:55:51<4:39:23, 35.29s/it] 56%|█████▌    | 598/1072 [5:56:26<4:38:52, 35.30s/it] 56%|█████▌    | 599/1072 [5:57:02<4:37:49, 35.24s/it] 56%|█████▌    | 600/1072 [5:57:37<4:36:49, 35.19s/it]                                                      {'loss': 1.7657, 'learning_rate': 1e-05, 'epoch': 1.12} 56%|█████▌    | 600/1072 [5:57:37<4:36:49, 35.19s/it] 56%|█████▌    | 601/1072 [5:59:19<7:14:11, 55.31s/it] 56%|█████▌    | 602/1072 [5:59:53<6:23:47, 48.99s/it] 56%|█████▋    | 603/1072 [6:00:27<5:48:29, 44.58s/it] 56%|█████▋    | 604/1072 [6:01:02<5:23:49, 41.52s/it] 56%|█████▋    | 605/1072 [6:01:36<5:06:16, 39.35s/it] 57%|█████▋    | 606/1072 [6:02:10<4:53:49, 37.83s/it] 57%|█████▋    | 607/1072 [6:02:44<4:44:12, 36.67s/it] 57%|█████▋    | 608/1072 [6:03:18<4:37:25, 35.87s/it] 57%|█████▋    | 609/1072 [6:03:53<4:32:56, 35.37s/it] 57%|█████▋    | 610/1072 [6:04:26<4:29:01, 34.94s/it]                                                      {'loss': 1.7769, 'learning_rate': 1e-05, 'epoch': 1.14} 57%|█████▋    | 610/1072 [6:04:26<4:29:01, 34.94s/it] 57%|█████▋    | 611/1072 [6:05:01<4:26:43, 34.71s/it] 57%|█████▋    | 612/1072 [6:05:34<4:23:55, 34.43s/it] 57%|█████▋    | 613/1072 [6:06:09<4:23:35, 34.46s/it] 57%|█████▋    | 614/1072 [6:06:43<4:22:25, 34.38s/it] 57%|█████▋    | 615/1072 [6:07:17<4:21:06, 34.28s/it] 57%|█████▋    | 616/1072 [6:07:51<4:18:56, 34.07s/it] 58%|█████▊    | 617/1072 [6:08:25<4:18:41, 34.11s/it] 58%|█████▊    | 618/1072 [6:08:59<4:18:41, 34.19s/it] 58%|█████▊    | 619/1072 [6:09:33<4:18:00, 34.17s/it] 58%|█████▊    | 620/1072 [6:10:08<4:18:47, 34.35s/it]                                                      {'loss': 1.7862, 'learning_rate': 1e-05, 'epoch': 1.16} 58%|█████▊    | 620/1072 [6:10:08<4:18:47, 34.35s/it] 58%|█████▊    | 621/1072 [6:10:43<4:18:36, 34.40s/it] 58%|█████▊    | 622/1072 [6:11:17<4:18:10, 34.42s/it] 58%|█████▊    | 623/1072 [6:11:51<4:17:09, 34.36s/it] 58%|█████▊    | 624/1072 [6:12:26<4:16:56, 34.41s/it] 58%|█████▊    | 625/1072 [6:13:01<4:18:09, 34.65s/it] 58%|█████▊    | 626/1072 [6:13:36<4:17:07, 34.59s/it] 58%|█████▊    | 627/1072 [6:14:11<4:17:31, 34.72s/it] 59%|█████▊    | 628/1072 [6:14:45<4:16:38, 34.68s/it] 59%|█████▊    | 629/1072 [6:15:19<4:14:50, 34.52s/it] 59%|█████▉    | 630/1072 [6:15:54<4:14:45, 34.58s/it]                                                      {'loss': 1.7783, 'learning_rate': 1e-05, 'epoch': 1.17} 59%|█████▉    | 630/1072 [6:15:54<4:14:45, 34.58s/it] 59%|█████▉    | 631/1072 [6:16:29<4:14:27, 34.62s/it] 59%|█████▉    | 632/1072 [6:17:03<4:13:29, 34.57s/it] 59%|█████▉    | 633/1072 [6:17:38<4:12:34, 34.52s/it] 59%|█████▉    | 634/1072 [6:18:12<4:12:06, 34.54s/it] 59%|█████▉    | 635/1072 [6:18:47<4:11:37, 34.55s/it] 59%|█████▉    | 636/1072 [6:19:22<4:11:35, 34.62s/it] 59%|█████▉    | 637/1072 [6:19:57<4:11:56, 34.75s/it] 60%|█████▉    | 638/1072 [6:20:31<4:11:21, 34.75s/it] 60%|█████▉    | 639/1072 [6:21:06<4:10:33, 34.72s/it] 60%|█████▉    | 640/1072 [6:21:41<4:10:04, 34.73s/it]                                                      {'loss': 1.7814, 'learning_rate': 1e-05, 'epoch': 1.19} 60%|█████▉    | 640/1072 [6:21:41<4:10:04, 34.73s/it] 60%|█████▉    | 641/1072 [6:22:16<4:10:34, 34.88s/it] 60%|█████▉    | 642/1072 [6:22:51<4:09:50, 34.86s/it] 60%|█████▉    | 643/1072 [6:23:26<4:10:08, 34.98s/it] 60%|██████    | 644/1072 [6:24:01<4:09:13, 34.94s/it] 60%|██████    | 645/1072 [6:24:36<4:09:41, 35.09s/it] 60%|██████    | 646/1072 [6:25:12<4:09:24, 35.13s/it] 60%|██████    | 647/1072 [6:25:47<4:09:45, 35.26s/it] 60%|██████    | 648/1072 [6:26:22<4:08:38, 35.19s/it] 61%|██████    | 649/1072 [6:26:57<4:07:17, 35.08s/it] 61%|██████    | 650/1072 [6:27:32<4:06:34, 35.06s/it]                                                      {'loss': 1.7962, 'learning_rate': 1e-05, 'epoch': 1.21} 61%|██████    | 650/1072 [6:27:32<4:06:34, 35.06s/it] 61%|██████    | 651/1072 [6:28:08<4:06:52, 35.18s/it] 61%|██████    | 652/1072 [6:28:43<4:06:32, 35.22s/it] 61%|██████    | 653/1072 [6:29:18<4:05:57, 35.22s/it] 61%|██████    | 654/1072 [6:29:53<4:05:24, 35.23s/it] 61%|██████    | 655/1072 [6:30:28<4:04:14, 35.14s/it] 61%|██████    | 656/1072 [6:31:04<4:04:23, 35.25s/it] 61%|██████▏   | 657/1072 [6:31:39<4:03:13, 35.16s/it] 61%|██████▏   | 658/1072 [6:32:15<4:04:53, 35.49s/it] 61%|██████▏   | 659/1072 [6:32:50<4:04:16, 35.49s/it] 62%|██████▏   | 660/1072 [6:33:26<4:02:51, 35.37s/it]                                                      {'loss': 1.7852, 'learning_rate': 1e-05, 'epoch': 1.23} 62%|██████▏   | 660/1072 [6:33:26<4:02:51, 35.37s/it] 62%|██████▏   | 661/1072 [6:34:01<4:03:00, 35.47s/it] 62%|██████▏   | 662/1072 [6:34:37<4:03:14, 35.60s/it] 62%|██████▏   | 663/1072 [6:35:12<4:01:37, 35.45s/it] 62%|██████▏   | 664/1072 [6:35:48<4:00:48, 35.41s/it] 62%|██████▏   | 665/1072 [6:36:23<3:59:33, 35.32s/it] 62%|██████▏   | 666/1072 [6:36:58<3:59:42, 35.42s/it] 62%|██████▏   | 667/1072 [6:37:34<3:58:58, 35.40s/it] 62%|██████▏   | 668/1072 [6:38:09<3:59:09, 35.52s/it] 62%|██████▏   | 669/1072 [6:38:45<3:58:02, 35.44s/it] 62%|██████▎   | 670/1072 [6:39:21<3:58:17, 35.57s/it]                                                      {'loss': 1.787, 'learning_rate': 1e-05, 'epoch': 1.25} 62%|██████▎   | 670/1072 [6:39:21<3:58:17, 35.57s/it] 63%|██████▎   | 671/1072 [6:39:56<3:58:06, 35.63s/it] 63%|██████▎   | 672/1072 [6:40:32<3:57:58, 35.70s/it] 63%|██████▎   | 673/1072 [6:41:07<3:56:02, 35.50s/it] 63%|██████▎   | 674/1072 [6:41:43<3:55:25, 35.49s/it] 63%|██████▎   | 675/1072 [6:42:18<3:54:46, 35.48s/it] 63%|██████▎   | 676/1072 [6:42:54<3:55:01, 35.61s/it] 63%|██████▎   | 677/1072 [6:43:30<3:54:25, 35.61s/it] 63%|██████▎   | 678/1072 [6:44:05<3:53:42, 35.59s/it] 63%|██████▎   | 679/1072 [6:44:41<3:52:42, 35.53s/it] 63%|██████▎   | 680/1072 [6:45:16<3:51:55, 35.50s/it]                                                      {'loss': 1.7764, 'learning_rate': 1e-05, 'epoch': 1.27} 63%|██████▎   | 680/1072 [6:45:16<3:51:55, 35.50s/it] 64%|██████▎   | 681/1072 [6:45:51<3:50:42, 35.40s/it] 64%|██████▎   | 682/1072 [6:46:26<3:48:38, 35.18s/it] 64%|██████▎   | 683/1072 [6:47:01<3:48:30, 35.24s/it] 64%|██████▍   | 684/1072 [6:47:37<3:48:04, 35.27s/it] 64%|██████▍   | 685/1072 [6:48:12<3:48:01, 35.35s/it] 64%|██████▍   | 686/1072 [6:48:47<3:47:08, 35.31s/it] 64%|██████▍   | 687/1072 [6:49:23<3:47:38, 35.48s/it] 64%|██████▍   | 688/1072 [6:49:59<3:47:44, 35.59s/it] 64%|██████▍   | 689/1072 [6:50:35<3:47:43, 35.67s/it] 64%|██████▍   | 690/1072 [6:51:11<3:47:28, 35.73s/it]                                                      {'loss': 1.7855, 'learning_rate': 1e-05, 'epoch': 1.29} 64%|██████▍   | 690/1072 [6:51:11<3:47:28, 35.73s/it] 64%|██████▍   | 691/1072 [6:51:47<3:47:05, 35.76s/it] 65%|██████▍   | 692/1072 [6:52:23<3:47:30, 35.92s/it] 65%|██████▍   | 693/1072 [6:52:59<3:46:43, 35.89s/it] 65%|██████▍   | 694/1072 [6:53:35<3:46:32, 35.96s/it] 65%|██████▍   | 695/1072 [6:54:10<3:45:05, 35.82s/it] 65%|██████▍   | 696/1072 [6:54:46<3:43:50, 35.72s/it] 65%|██████▌   | 697/1072 [6:55:21<3:42:37, 35.62s/it] 65%|██████▌   | 698/1072 [6:55:57<3:41:23, 35.52s/it] 65%|██████▌   | 699/1072 [6:56:32<3:40:57, 35.54s/it] 65%|██████▌   | 700/1072 [6:57:08<3:40:26, 35.55s/it]                                                      {'loss': 1.793, 'learning_rate': 1e-05, 'epoch': 1.3} 65%|██████▌   | 700/1072 [6:57:08<3:40:26, 35.55s/it] 65%|██████▌   | 701/1072 [6:58:41<5:26:01, 52.73s/it] 65%|██████▌   | 702/1072 [6:59:15<4:51:25, 47.26s/it] 66%|██████▌   | 703/1072 [6:59:50<4:27:08, 43.44s/it] 66%|██████▌   | 704/1072 [7:00:23<4:08:52, 40.58s/it] 66%|██████▌   | 705/1072 [7:00:58<3:56:47, 38.71s/it] 66%|██████▌   | 706/1072 [7:01:32<3:48:09, 37.40s/it] 66%|██████▌   | 707/1072 [7:02:07<3:42:30, 36.58s/it] 66%|██████▌   | 708/1072 [7:02:41<3:37:28, 35.85s/it] 66%|██████▌   | 709/1072 [7:03:15<3:33:41, 35.32s/it] 66%|██████▌   | 710/1072 [7:03:50<3:31:44, 35.09s/it]                                                      {'loss': 1.7933, 'learning_rate': 1e-05, 'epoch': 1.32} 66%|██████▌   | 710/1072 [7:03:50<3:31:44, 35.09s/it] 66%|██████▋   | 711/1072 [7:04:24<3:29:14, 34.78s/it] 66%|██████▋   | 712/1072 [7:04:58<3:27:16, 34.55s/it] 67%|██████▋   | 713/1072 [7:05:32<3:26:05, 34.44s/it] 67%|██████▋   | 714/1072 [7:06:07<3:26:50, 34.67s/it] 67%|██████▋   | 715/1072 [7:06:42<3:26:52, 34.77s/it] 67%|██████▋   | 716/1072 [7:07:17<3:26:21, 34.78s/it] 67%|██████▋   | 717/1072 [7:07:52<3:25:51, 34.79s/it] 67%|██████▋   | 718/1072 [7:08:26<3:25:00, 34.75s/it] 67%|██████▋   | 719/1072 [7:09:01<3:24:47, 34.81s/it] 67%|██████▋   | 720/1072 [7:09:36<3:24:27, 34.85s/it]                                                      {'loss': 1.7778, 'learning_rate': 1e-05, 'epoch': 1.34} 67%|██████▋   | 720/1072 [7:09:36<3:24:27, 34.85s/it] 67%|██████▋   | 721/1072 [7:10:12<3:24:58, 35.04s/it] 67%|██████▋   | 722/1072 [7:10:46<3:23:40, 34.92s/it] 67%|██████▋   | 723/1072 [7:11:21<3:22:52, 34.88s/it] 68%|██████▊   | 724/1072 [7:11:56<3:22:48, 34.97s/it] 68%|██████▊   | 725/1072 [7:12:31<3:21:42, 34.88s/it] 68%|██████▊   | 726/1072 [7:13:06<3:21:32, 34.95s/it] 68%|██████▊   | 727/1072 [7:13:41<3:21:12, 34.99s/it] 68%|██████▊   | 728/1072 [7:14:16<3:20:13, 34.92s/it] 68%|██████▊   | 729/1072 [7:14:51<3:19:50, 34.96s/it] 68%|██████▊   | 730/1072 [7:15:26<3:20:04, 35.10s/it]                                                      {'loss': 1.7954, 'learning_rate': 1e-05, 'epoch': 1.36} 68%|██████▊   | 730/1072 [7:15:26<3:20:04, 35.10s/it] 68%|██████▊   | 731/1072 [7:16:02<3:20:13, 35.23s/it] 68%|██████▊   | 732/1072 [7:16:37<3:19:25, 35.19s/it] 68%|██████▊   | 733/1072 [7:17:13<3:19:47, 35.36s/it] 68%|██████▊   | 734/1072 [7:17:48<3:19:28, 35.41s/it] 69%|██████▊   | 735/1072 [7:18:24<3:18:50, 35.40s/it] 69%|██████▊   | 736/1072 [7:18:59<3:17:33, 35.28s/it] 69%|██████▉   | 737/1072 [7:19:34<3:16:37, 35.22s/it] 69%|██████▉   | 738/1072 [7:20:09<3:16:06, 35.23s/it] 69%|██████▉   | 739/1072 [7:20:44<3:15:26, 35.22s/it] 69%|██████▉   | 740/1072 [7:21:19<3:13:36, 34.99s/it]                                                      {'loss': 1.7788, 'learning_rate': 1e-05, 'epoch': 1.38} 69%|██████▉   | 740/1072 [7:21:19<3:13:36, 34.99s/it] 69%|██████▉   | 741/1072 [7:21:54<3:12:51, 34.96s/it] 69%|██████▉   | 742/1072 [7:22:29<3:12:45, 35.05s/it] 69%|██████▉   | 743/1072 [7:23:03<3:11:19, 34.89s/it] 69%|██████▉   | 744/1072 [7:23:38<3:09:47, 34.72s/it] 69%|██████▉   | 745/1072 [7:24:13<3:09:42, 34.81s/it] 70%|██████▉   | 746/1072 [7:24:48<3:09:59, 34.97s/it] 70%|██████▉   | 747/1072 [7:25:24<3:10:30, 35.17s/it] 70%|██████▉   | 748/1072 [7:25:59<3:09:28, 35.09s/it] 70%|██████▉   | 749/1072 [7:26:34<3:09:22, 35.18s/it] 70%|██████▉   | 750/1072 [7:27:09<3:08:42, 35.16s/it]                                                      {'loss': 1.799, 'learning_rate': 1e-05, 'epoch': 1.4} 70%|██████▉   | 750/1072 [7:27:09<3:08:42, 35.16s/it] 70%|███████   | 751/1072 [7:27:45<3:09:24, 35.40s/it] 70%|███████   | 752/1072 [7:28:21<3:08:55, 35.42s/it] 70%|███████   | 753/1072 [7:28:56<3:08:37, 35.48s/it] 70%|███████   | 754/1072 [7:29:32<3:08:04, 35.49s/it] 70%|███████   | 755/1072 [7:30:07<3:07:07, 35.42s/it] 71%|███████   | 756/1072 [7:30:42<3:06:30, 35.41s/it] 71%|███████   | 757/1072 [7:31:18<3:06:45, 35.57s/it] 71%|███████   | 758/1072 [7:31:54<3:06:34, 35.65s/it] 71%|███████   | 759/1072 [7:32:30<3:06:45, 35.80s/it] 71%|███████   | 760/1072 [7:33:06<3:05:54, 35.75s/it]                                                      {'loss': 1.7825, 'learning_rate': 1e-05, 'epoch': 1.42} 71%|███████   | 760/1072 [7:33:06<3:05:54, 35.75s/it] 71%|███████   | 761/1072 [7:33:42<3:05:59, 35.88s/it] 71%|███████   | 762/1072 [7:34:18<3:05:02, 35.81s/it] 71%|███████   | 763/1072 [7:34:54<3:04:45, 35.87s/it] 71%|███████▏  | 764/1072 [7:35:30<3:04:24, 35.92s/it] 71%|███████▏  | 765/1072 [7:36:06<3:04:01, 35.97s/it] 71%|███████▏  | 766/1072 [7:36:42<3:03:46, 36.03s/it] 72%|███████▏  | 767/1072 [7:37:19<3:04:04, 36.21s/it] 72%|███████▏  | 768/1072 [7:37:55<3:03:22, 36.19s/it] 72%|███████▏  | 769/1072 [7:38:31<3:02:24, 36.12s/it] 72%|███████▏  | 770/1072 [7:39:07<3:01:38, 36.09s/it]                                                      {'loss': 1.7964, 'learning_rate': 1e-05, 'epoch': 1.44} 72%|███████▏  | 770/1072 [7:39:07<3:01:38, 36.09s/it] 72%|███████▏  | 771/1072 [7:39:43<3:01:44, 36.23s/it] 72%|███████▏  | 772/1072 [7:40:19<3:00:13, 36.05s/it] 72%|███████▏  | 773/1072 [7:40:55<3:00:10, 36.16s/it] 72%|███████▏  | 774/1072 [7:41:32<2:59:42, 36.18s/it] 72%|███████▏  | 775/1072 [7:42:06<2:57:15, 35.81s/it] 72%|███████▏  | 776/1072 [7:42:42<2:55:49, 35.64s/it] 72%|███████▏  | 777/1072 [7:43:17<2:54:59, 35.59s/it] 73%|███████▎  | 778/1072 [7:43:53<2:54:30, 35.61s/it] 73%|███████▎  | 779/1072 [7:44:28<2:53:40, 35.57s/it] 73%|███████▎  | 780/1072 [7:45:03<2:52:25, 35.43s/it]                                                      {'loss': 1.7995, 'learning_rate': 1e-05, 'epoch': 1.45} 73%|███████▎  | 780/1072 [7:45:03<2:52:25, 35.43s/it] 73%|███████▎  | 781/1072 [7:45:39<2:52:01, 35.47s/it] 73%|███████▎  | 782/1072 [7:46:15<2:52:27, 35.68s/it] 73%|███████▎  | 783/1072 [7:46:51<2:51:37, 35.63s/it] 73%|███████▎  | 784/1072 [7:47:27<2:51:49, 35.80s/it] 73%|███████▎  | 785/1072 [7:48:03<2:51:48, 35.92s/it] 73%|███████▎  | 786/1072 [7:48:39<2:50:46, 35.83s/it] 73%|███████▎  | 787/1072 [7:49:15<2:50:26, 35.88s/it] 74%|███████▎  | 788/1072 [7:49:50<2:49:26, 35.80s/it] 74%|███████▎  | 789/1072 [7:50:25<2:47:49, 35.58s/it] 74%|███████▎  | 790/1072 [7:51:01<2:47:17, 35.60s/it]                                                      {'loss': 1.7974, 'learning_rate': 1e-05, 'epoch': 1.47} 74%|███████▎  | 790/1072 [7:51:01<2:47:17, 35.60s/it] 74%|███████▍  | 791/1072 [7:51:37<2:47:21, 35.73s/it] 74%|███████▍  | 792/1072 [7:52:12<2:46:11, 35.61s/it] 74%|███████▍  | 793/1072 [7:52:48<2:45:17, 35.55s/it] 74%|███████▍  | 794/1072 [7:53:24<2:45:03, 35.63s/it] 74%|███████▍  | 795/1072 [7:53:59<2:44:31, 35.64s/it] 74%|███████▍  | 796/1072 [7:54:35<2:43:59, 35.65s/it] 74%|███████▍  | 797/1072 [7:55:11<2:44:00, 35.78s/it] 74%|███████▍  | 798/1072 [7:55:47<2:44:06, 35.94s/it] 75%|███████▍  | 799/1072 [7:56:23<2:43:28, 35.93s/it] 75%|███████▍  | 800/1072 [7:57:00<2:43:29, 36.06s/it]                                                      {'loss': 1.7964, 'learning_rate': 1e-05, 'epoch': 1.49} 75%|███████▍  | 800/1072 [7:57:00<2:43:29, 36.06s/it] 75%|███████▍  | 801/1072 [7:58:31<3:57:27, 52.57s/it] 75%|███████▍  | 802/1072 [7:59:06<3:32:44, 47.28s/it] 75%|███████▍  | 803/1072 [7:59:40<3:14:42, 43.43s/it] 75%|███████▌  | 804/1072 [8:00:14<3:01:33, 40.65s/it] 75%|███████▌  | 805/1072 [8:00:48<2:52:15, 38.71s/it] 75%|███████▌  | 806/1072 [8:01:22<2:45:20, 37.29s/it] 75%|███████▌  | 807/1072 [8:01:57<2:40:35, 36.36s/it] 75%|███████▌  | 808/1072 [8:02:31<2:37:25, 35.78s/it] 75%|███████▌  | 809/1072 [8:03:06<2:35:22, 35.45s/it] 76%|███████▌  | 810/1072 [8:03:40<2:33:21, 35.12s/it]                                                      {'loss': 1.8133, 'learning_rate': 1e-05, 'epoch': 1.51} 76%|███████▌  | 810/1072 [8:03:40<2:33:21, 35.12s/it] 76%|███████▌  | 811/1072 [8:04:15<2:32:23, 35.03s/it] 76%|███████▌  | 812/1072 [8:04:50<2:31:23, 34.94s/it] 76%|███████▌  | 813/1072 [8:05:25<2:30:59, 34.98s/it] 76%|███████▌  | 814/1072 [8:06:00<2:30:28, 35.00s/it] 76%|███████▌  | 815/1072 [8:06:34<2:29:08, 34.82s/it] 76%|███████▌  | 816/1072 [8:07:09<2:28:09, 34.73s/it] 76%|███████▌  | 817/1072 [8:07:44<2:28:12, 34.87s/it] 76%|███████▋  | 818/1072 [8:08:18<2:26:58, 34.72s/it] 76%|███████▋  | 819/1072 [8:08:53<2:26:07, 34.65s/it] 76%|███████▋  | 820/1072 [8:09:27<2:25:25, 34.62s/it]                                                      {'loss': 1.7946, 'learning_rate': 1e-05, 'epoch': 1.53} 76%|███████▋  | 820/1072 [8:09:27<2:25:25, 34.62s/it] 77%|███████▋  | 821/1072 [8:10:03<2:25:45, 34.84s/it] 77%|███████▋  | 822/1072 [8:10:37<2:25:07, 34.83s/it] 77%|███████▋  | 823/1072 [8:11:12<2:24:49, 34.90s/it] 77%|███████▋  | 824/1072 [8:11:48<2:24:43, 35.01s/it] 77%|███████▋  | 825/1072 [8:12:23<2:24:56, 35.21s/it] 77%|███████▋  | 826/1072 [8:12:59<2:25:04, 35.39s/it] 77%|███████▋  | 827/1072 [8:13:35<2:25:01, 35.52s/it] 77%|███████▋  | 828/1072 [8:14:11<2:24:57, 35.65s/it] 77%|███████▋  | 829/1072 [8:14:47<2:25:05, 35.83s/it] 77%|███████▋  | 830/1072 [8:15:23<2:24:23, 35.80s/it]                                                      {'loss': 1.8026, 'learning_rate': 1e-05, 'epoch': 1.55} 77%|███████▋  | 830/1072 [8:15:23<2:24:23, 35.80s/it] 78%|███████▊  | 831/1072 [8:15:59<2:24:26, 35.96s/it] 78%|███████▊  | 832/1072 [8:16:35<2:23:39, 35.91s/it] 78%|███████▊  | 833/1072 [8:17:11<2:23:17, 35.97s/it] 78%|███████▊  | 834/1072 [8:17:47<2:22:49, 36.00s/it] 78%|███████▊  | 835/1072 [8:18:23<2:22:05, 35.97s/it] 78%|███████▊  | 836/1072 [8:18:59<2:20:49, 35.80s/it] 78%|███████▊  | 837/1072 [8:19:34<2:20:03, 35.76s/it] 78%|███████▊  | 838/1072 [8:20:10<2:19:50, 35.86s/it] 78%|███████▊  | 839/1072 [8:20:46<2:19:22, 35.89s/it] 78%|███████▊  | 840/1072 [8:21:22<2:18:44, 35.88s/it]                                                      {'loss': 1.7872, 'learning_rate': 1e-05, 'epoch': 1.57} 78%|███████▊  | 840/1072 [8:21:22<2:18:44, 35.88s/it] 78%|███████▊  | 841/1072 [8:21:59<2:18:43, 36.03s/it] 79%|███████▊  | 842/1072 [8:22:35<2:18:04, 36.02s/it] 79%|███████▊  | 843/1072 [8:23:10<2:16:45, 35.83s/it] 79%|███████▊  | 844/1072 [8:23:45<2:15:45, 35.72s/it] 79%|███████▉  | 845/1072 [8:24:21<2:15:14, 35.75s/it] 79%|███████▉  | 846/1072 [8:24:57<2:14:42, 35.76s/it] 79%|███████▉  | 847/1072 [8:25:33<2:14:12, 35.79s/it] 79%|███████▉  | 848/1072 [8:26:09<2:13:47, 35.84s/it] 79%|███████▉  | 849/1072 [8:26:44<2:12:57, 35.77s/it] 79%|███████▉  | 850/1072 [8:27:20<2:12:02, 35.69s/it]                                                      {'loss': 1.805, 'learning_rate': 1e-05, 'epoch': 1.58} 79%|███████▉  | 850/1072 [8:27:20<2:12:02, 35.69s/it] 79%|███████▉  | 851/1072 [8:27:56<2:11:41, 35.76s/it] 79%|███████▉  | 852/1072 [8:28:32<2:11:25, 35.84s/it] 80%|███████▉  | 853/1072 [8:29:08<2:10:48, 35.84s/it] 80%|███████▉  | 854/1072 [8:29:43<2:10:06, 35.81s/it] 80%|███████▉  | 855/1072 [8:30:19<2:09:19, 35.76s/it] 80%|███████▉  | 856/1072 [8:30:55<2:08:53, 35.80s/it] 80%|███████▉  | 857/1072 [8:31:31<2:08:07, 35.76s/it] 80%|████████  | 858/1072 [8:32:06<2:07:31, 35.75s/it] 80%|████████  | 859/1072 [8:32:42<2:06:52, 35.74s/it] 80%|████████  | 860/1072 [8:33:18<2:06:05, 35.69s/it]                                                      {'loss': 1.7979, 'learning_rate': 1e-05, 'epoch': 1.6} 80%|████████  | 860/1072 [8:33:18<2:06:05, 35.69s/it] 80%|████████  | 861/1072 [8:33:54<2:05:46, 35.76s/it] 80%|████████  | 862/1072 [8:34:29<2:05:17, 35.80s/it] 81%|████████  | 863/1072 [8:35:05<2:04:48, 35.83s/it] 81%|████████  | 864/1072 [8:35:41<2:04:05, 35.80s/it] 81%|████████  | 865/1072 [8:36:17<2:03:27, 35.78s/it] 81%|████████  | 866/1072 [8:36:52<2:02:10, 35.58s/it] 81%|████████  | 867/1072 [8:37:28<2:01:45, 35.64s/it] 81%|████████  | 868/1072 [8:38:03<2:00:32, 35.45s/it] 81%|████████  | 869/1072 [8:38:37<1:59:10, 35.22s/it] 81%|████████  | 870/1072 [8:39:13<1:58:37, 35.23s/it]                                                      {'loss': 1.8096, 'learning_rate': 1e-05, 'epoch': 1.62} 81%|████████  | 870/1072 [8:39:13<1:58:37, 35.23s/it] 81%|████████▏ | 871/1072 [8:39:48<1:57:56, 35.21s/it] 81%|████████▏ | 872/1072 [8:40:23<1:57:23, 35.22s/it] 81%|████████▏ | 873/1072 [8:40:59<1:57:02, 35.29s/it] 82%|████████▏ | 874/1072 [8:41:34<1:56:49, 35.40s/it] 82%|████████▏ | 875/1072 [8:42:10<1:56:24, 35.45s/it] 82%|████████▏ | 876/1072 [8:42:45<1:56:03, 35.53s/it] 82%|████████▏ | 877/1072 [8:43:21<1:55:29, 35.54s/it] 82%|████████▏ | 878/1072 [8:43:57<1:54:57, 35.55s/it] 82%|████████▏ | 879/1072 [8:44:33<1:55:11, 35.81s/it] 82%|████████▏ | 880/1072 [8:45:08<1:53:59, 35.62s/it]                                                      {'loss': 1.8163, 'learning_rate': 1e-05, 'epoch': 1.64} 82%|████████▏ | 880/1072 [8:45:08<1:53:59, 35.62s/it] 82%|████████▏ | 881/1072 [8:45:43<1:52:52, 35.46s/it] 82%|████████▏ | 882/1072 [8:46:19<1:52:10, 35.43s/it] 82%|████████▏ | 883/1072 [8:46:54<1:51:18, 35.34s/it] 82%|████████▏ | 884/1072 [8:47:29<1:50:40, 35.32s/it] 83%|████████▎ | 885/1072 [8:48:04<1:50:02, 35.31s/it] 83%|████████▎ | 886/1072 [8:48:39<1:49:16, 35.25s/it] 83%|████████▎ | 887/1072 [8:49:15<1:48:56, 35.33s/it] 83%|████████▎ | 888/1072 [8:49:50<1:48:23, 35.35s/it] 83%|████████▎ | 889/1072 [8:50:26<1:47:41, 35.31s/it] 83%|████████▎ | 890/1072 [8:51:01<1:47:30, 35.44s/it]                                                      {'loss': 1.7949, 'learning_rate': 1e-05, 'epoch': 1.66} 83%|████████▎ | 890/1072 [8:51:01<1:47:30, 35.44s/it] 83%|████████▎ | 891/1072 [8:51:37<1:47:13, 35.55s/it] 83%|████████▎ | 892/1072 [8:52:14<1:47:27, 35.82s/it] 83%|████████▎ | 893/1072 [8:52:49<1:46:40, 35.76s/it] 83%|████████▎ | 894/1072 [8:53:25<1:46:02, 35.75s/it] 83%|████████▎ | 895/1072 [8:54:00<1:45:08, 35.64s/it] 84%|████████▎ | 896/1072 [8:54:36<1:44:26, 35.61s/it] 84%|████████▎ | 897/1072 [8:55:11<1:43:51, 35.61s/it] 84%|████████▍ | 898/1072 [8:55:48<1:43:48, 35.80s/it] 84%|████████▍ | 899/1072 [8:56:24<1:43:13, 35.80s/it] 84%|████████▍ | 900/1072 [8:56:59<1:42:43, 35.84s/it]                                                      {'loss': 1.7795, 'learning_rate': 1e-05, 'epoch': 1.68} 84%|████████▍ | 900/1072 [8:56:59<1:42:43, 35.84s/it] 84%|████████▍ | 901/1072 [8:58:31<2:29:25, 52.43s/it] 84%|████████▍ | 902/1072 [8:59:05<2:13:25, 47.09s/it] 84%|████████▍ | 903/1072 [8:59:39<2:01:46, 43.23s/it] 84%|████████▍ | 904/1072 [9:00:14<1:53:28, 40.52s/it] 84%|████████▍ | 905/1072 [9:00:48<1:47:45, 38.71s/it] 85%|████████▍ | 906/1072 [9:01:23<1:43:47, 37.51s/it] 85%|████████▍ | 907/1072 [9:01:57<1:40:29, 36.54s/it] 85%|████████▍ | 908/1072 [9:02:32<1:38:08, 35.91s/it] 85%|████████▍ | 909/1072 [9:03:06<1:36:39, 35.58s/it] 85%|████████▍ | 910/1072 [9:03:41<1:35:26, 35.35s/it]                                                      {'loss': 1.7848, 'learning_rate': 1e-05, 'epoch': 1.7} 85%|████████▍ | 910/1072 [9:03:41<1:35:26, 35.35s/it] 85%|████████▍ | 911/1072 [9:04:16<1:34:17, 35.14s/it] 85%|████████▌ | 912/1072 [9:04:50<1:33:01, 34.89s/it] 85%|████████▌ | 913/1072 [9:05:25<1:32:24, 34.87s/it] 85%|████████▌ | 914/1072 [9:06:00<1:31:54, 34.90s/it] 85%|████████▌ | 915/1072 [9:06:34<1:30:44, 34.68s/it] 85%|████████▌ | 916/1072 [9:07:09<1:30:34, 34.84s/it] 86%|████████▌ | 917/1072 [9:07:44<1:29:54, 34.80s/it] 86%|████████▌ | 918/1072 [9:08:19<1:29:19, 34.80s/it] 86%|████████▌ | 919/1072 [9:08:54<1:29:12, 34.99s/it] 86%|████████▌ | 920/1072 [9:09:30<1:29:07, 35.18s/it]                                                      {'loss': 1.8099, 'learning_rate': 1e-05, 'epoch': 1.71} 86%|████████▌ | 920/1072 [9:09:30<1:29:07, 35.18s/it] 86%|████████▌ | 921/1072 [9:10:05<1:28:47, 35.28s/it] 86%|████████▌ | 922/1072 [9:10:41<1:28:05, 35.24s/it] 86%|████████▌ | 923/1072 [9:11:15<1:27:09, 35.10s/it] 86%|████████▌ | 924/1072 [9:11:51<1:26:44, 35.17s/it] 86%|████████▋ | 925/1072 [9:12:26<1:26:18, 35.23s/it] 86%|████████▋ | 926/1072 [9:13:02<1:26:12, 35.43s/it] 86%|████████▋ | 927/1072 [9:13:37<1:25:36, 35.43s/it] 87%|████████▋ | 928/1072 [9:14:13<1:25:34, 35.66s/it] 87%|████████▋ | 929/1072 [9:14:50<1:25:22, 35.82s/it] 87%|████████▋ | 930/1072 [9:15:26<1:24:56, 35.89s/it]                                                      {'loss': 1.8043, 'learning_rate': 1e-05, 'epoch': 1.73} 87%|████████▋ | 930/1072 [9:15:26<1:24:56, 35.89s/it] 87%|████████▋ | 931/1072 [9:16:02<1:24:28, 35.95s/it] 87%|████████▋ | 932/1072 [9:16:37<1:23:39, 35.85s/it] 87%|████████▋ | 933/1072 [9:17:13<1:22:48, 35.74s/it] 87%|████████▋ | 934/1072 [9:17:48<1:22:03, 35.67s/it] 87%|████████▋ | 935/1072 [9:18:24<1:21:15, 35.59s/it] 87%|████████▋ | 936/1072 [9:18:59<1:20:34, 35.54s/it] 87%|████████▋ | 937/1072 [9:19:35<1:19:45, 35.45s/it] 88%|████████▊ | 938/1072 [9:20:10<1:19:09, 35.44s/it] 88%|████████▊ | 939/1072 [9:20:45<1:18:34, 35.45s/it] 88%|████████▊ | 940/1072 [9:21:21<1:17:51, 35.39s/it]                                                      {'loss': 1.7912, 'learning_rate': 1e-05, 'epoch': 1.75} 88%|████████▊ | 940/1072 [9:21:21<1:17:51, 35.39s/it] 88%|████████▊ | 941/1072 [9:21:56<1:17:16, 35.39s/it] 88%|████████▊ | 942/1072 [9:22:31<1:16:42, 35.40s/it] 88%|████████▊ | 943/1072 [9:23:07<1:15:55, 35.32s/it] 88%|████████▊ | 944/1072 [9:23:42<1:15:27, 35.37s/it] 88%|████████▊ | 945/1072 [9:24:17<1:14:45, 35.32s/it] 88%|████████▊ | 946/1072 [9:24:53<1:14:16, 35.37s/it] 88%|████████▊ | 947/1072 [9:25:28<1:13:37, 35.34s/it] 88%|████████▊ | 948/1072 [9:26:04<1:13:14, 35.44s/it] 89%|████████▊ | 949/1072 [9:26:39<1:12:48, 35.51s/it] 89%|████████▊ | 950/1072 [9:27:15<1:12:29, 35.65s/it]                                                      {'loss': 1.7936, 'learning_rate': 1e-05, 'epoch': 1.77} 89%|████████▊ | 950/1072 [9:27:15<1:12:29, 35.65s/it] 89%|████████▊ | 951/1072 [9:27:51<1:11:52, 35.64s/it] 89%|████████▉ | 952/1072 [9:28:27<1:11:32, 35.77s/it] 89%|████████▉ | 953/1072 [9:29:03<1:10:53, 35.74s/it] 89%|████████▉ | 954/1072 [9:29:39<1:10:23, 35.79s/it] 89%|████████▉ | 955/1072 [9:30:15<1:09:56, 35.87s/it] 89%|████████▉ | 956/1072 [9:30:51<1:09:27, 35.93s/it] 89%|████████▉ | 957/1072 [9:31:27<1:08:52, 35.94s/it] 89%|████████▉ | 958/1072 [9:32:02<1:08:07, 35.86s/it] 89%|████████▉ | 959/1072 [9:32:38<1:07:18, 35.74s/it] 90%|████████▉ | 960/1072 [9:33:13<1:06:35, 35.67s/it]                                                      {'loss': 1.7962, 'learning_rate': 1e-05, 'epoch': 1.79} 90%|████████▉ | 960/1072 [9:33:13<1:06:35, 35.67s/it] 90%|████████▉ | 961/1072 [9:33:48<1:05:40, 35.50s/it] 90%|████████▉ | 962/1072 [9:34:23<1:04:35, 35.23s/it] 90%|████████▉ | 963/1072 [9:34:58<1:03:38, 35.03s/it] 90%|████████▉ | 964/1072 [9:35:33<1:03:19, 35.18s/it] 90%|█████████ | 965/1072 [9:36:08<1:02:38, 35.13s/it] 90%|█████████ | 966/1072 [9:36:44<1:02:15, 35.24s/it] 90%|█████████ | 967/1072 [9:37:19<1:01:41, 35.25s/it] 90%|█████████ | 968/1072 [9:37:54<1:01:10, 35.29s/it] 90%|█████████ | 969/1072 [9:38:29<1:00:25, 35.20s/it] 90%|█████████ | 970/1072 [9:39:04<59:34, 35.05s/it]                                                      {'loss': 1.7924, 'learning_rate': 1e-05, 'epoch': 1.81} 90%|█████████ | 970/1072 [9:39:04<59:34, 35.05s/it] 91%|█████████ | 971/1072 [9:39:38<58:41, 34.87s/it] 91%|█████████ | 972/1072 [9:40:14<58:20, 35.01s/it] 91%|█████████ | 973/1072 [9:40:48<57:27, 34.82s/it] 91%|█████████ | 974/1072 [9:41:23<56:40, 34.69s/it] 91%|█████████ | 975/1072 [9:41:57<56:03, 34.68s/it] 91%|█████████ | 976/1072 [9:42:33<55:51, 34.91s/it] 91%|█████████ | 977/1072 [9:43:08<55:21, 34.96s/it] 91%|█████████ | 978/1072 [9:43:43<54:52, 35.03s/it] 91%|█████████▏| 979/1072 [9:44:18<54:25, 35.11s/it] 91%|█████████▏| 980/1072 [9:44:53<53:50, 35.11s/it]                                                    {'loss': 1.8065, 'learning_rate': 1e-05, 'epoch': 1.83} 91%|█████████▏| 980/1072 [9:44:53<53:50, 35.11s/it] 92%|█████████▏| 981/1072 [9:45:28<53:12, 35.08s/it] 92%|█████████▏| 982/1072 [9:46:03<52:31, 35.02s/it] 92%|█████████▏| 983/1072 [9:46:38<51:49, 34.94s/it] 92%|█████████▏| 984/1072 [9:47:13<51:07, 34.86s/it] 92%|█████████▏| 985/1072 [9:47:47<50:27, 34.79s/it] 92%|█████████▏| 986/1072 [9:48:22<49:43, 34.69s/it] 92%|█████████▏| 987/1072 [9:48:56<48:55, 34.54s/it] 92%|█████████▏| 988/1072 [9:49:30<48:08, 34.38s/it] 92%|█████████▏| 989/1072 [9:50:05<47:39, 34.46s/it] 92%|█████████▏| 990/1072 [9:50:39<47:01, 34.40s/it]                                                    {'loss': 1.8015, 'learning_rate': 1e-05, 'epoch': 1.85} 92%|█████████▏| 990/1072 [9:50:39<47:01, 34.40s/it] 92%|█████████▏| 991/1072 [9:51:13<46:18, 34.31s/it] 93%|█████████▎| 992/1072 [9:51:48<45:53, 34.42s/it] 93%|█████████▎| 993/1072 [9:52:22<45:17, 34.40s/it] 93%|█████████▎| 994/1072 [9:52:57<44:55, 34.55s/it] 93%|█████████▎| 995/1072 [9:53:31<44:15, 34.49s/it] 93%|█████████▎| 996/1072 [9:54:06<43:42, 34.50s/it] 93%|█████████▎| 997/1072 [9:54:40<42:53, 34.31s/it] 93%|█████████▎| 998/1072 [9:55:13<42:04, 34.12s/it] 93%|█████████▎| 999/1072 [9:55:47<41:17, 33.94s/it] 93%|█████████▎| 1000/1072 [9:56:21<40:37, 33.86s/it]                                                     {'loss': 1.7924, 'learning_rate': 1e-05, 'epoch': 1.86} 93%|█████████▎| 1000/1072 [9:56:21<40:37, 33.86s/it] 93%|█████████▎| 1001/1072 [9:57:48<59:15, 50.08s/it] 93%|█████████▎| 1002/1072 [9:58:22<52:31, 45.02s/it] 94%|█████████▎| 1003/1072 [9:58:55<47:41, 41.47s/it] 94%|█████████▎| 1004/1072 [9:59:28<44:11, 38.99s/it] 94%|█████████▍| 1005/1072 [10:00:01<41:30, 37.17s/it] 94%|█████████▍| 1006/1072 [10:00:34<39:33, 35.96s/it] 94%|█████████▍| 1007/1072 [10:01:07<38:05, 35.16s/it] 94%|█████████▍| 1008/1072 [10:01:41<36:58, 34.67s/it] 94%|█████████▍| 1009/1072 [10:02:15<36:05, 34.37s/it] 94%|█████████▍| 1010/1072 [10:02:48<35:06, 33.97s/it]                                                      {'loss': 1.807, 'learning_rate': 1e-05, 'epoch': 1.88} 94%|█████████▍| 1010/1072 [10:02:48<35:06, 33.97s/it] 94%|█████████▍| 1011/1072 [10:03:21<34:18, 33.75s/it] 94%|█████████▍| 1012/1072 [10:03:54<33:39, 33.67s/it] 94%|█████████▍| 1013/1072 [10:04:28<32:57, 33.52s/it] 95%|█████████▍| 1014/1072 [10:05:01<32:19, 33.44s/it] 95%|█████████▍| 1015/1072 [10:05:34<31:44, 33.42s/it] 95%|█████████▍| 1016/1072 [10:06:08<31:17, 33.52s/it] 95%|█████████▍| 1017/1072 [10:06:41<30:43, 33.52s/it] 95%|█████████▍| 1018/1072 [10:07:15<30:06, 33.45s/it] 95%|█████████▌| 1019/1072 [10:07:48<29:32, 33.44s/it] 95%|█████████▌| 1020/1072 [10:08:22<29:09, 33.65s/it]                                                      {'loss': 1.7942, 'learning_rate': 1e-05, 'epoch': 1.9} 95%|█████████▌| 1020/1072 [10:08:22<29:09, 33.65s/it] 95%|█████████▌| 1021/1072 [10:08:56<28:42, 33.77s/it] 95%|█████████▌| 1022/1072 [10:09:30<28:13, 33.87s/it] 95%|█████████▌| 1023/1072 [10:10:05<27:52, 34.13s/it] 96%|█████████▌| 1024/1072 [10:10:39<27:18, 34.14s/it] 96%|█████████▌| 1025/1072 [10:11:14<26:49, 34.25s/it] 96%|█████████▌| 1026/1072 [10:11:48<26:10, 34.14s/it] 96%|█████████▌| 1027/1072 [10:12:22<25:37, 34.16s/it] 96%|█████████▌| 1028/1072 [10:12:56<25:03, 34.18s/it] 96%|█████████▌| 1029/1072 [10:13:30<24:24, 34.06s/it] 96%|█████████▌| 1030/1072 [10:14:05<24:06, 34.44s/it]                                                      {'loss': 1.8098, 'learning_rate': 1e-05, 'epoch': 1.92} 96%|█████████▌| 1030/1072 [10:14:05<24:06, 34.44s/it] 96%|█████████▌| 1031/1072 [10:14:40<23:36, 34.54s/it] 96%|█████████▋| 1032/1072 [10:15:15<23:08, 34.70s/it] 96%|█████████▋| 1033/1072 [10:15:50<22:34, 34.74s/it] 96%|█████████▋| 1034/1072 [10:16:25<21:59, 34.71s/it] 97%|█████████▋| 1035/1072 [10:16:59<21:22, 34.66s/it] 97%|█████████▋| 1036/1072 [10:17:34<20:48, 34.69s/it] 97%|█████████▋| 1037/1072 [10:18:09<20:15, 34.74s/it] 97%|█████████▋| 1038/1072 [10:18:44<19:45, 34.86s/it] 97%|█████████▋| 1039/1072 [10:19:19<19:11, 34.89s/it] 97%|█████████▋| 1040/1072 [10:19:53<18:34, 34.81s/it]                                                      {'loss': 1.8106, 'learning_rate': 1e-05, 'epoch': 1.94} 97%|█████████▋| 1040/1072 [10:19:53<18:34, 34.81s/it] 97%|█████████▋| 1041/1072 [10:20:28<18:00, 34.86s/it] 97%|█████████▋| 1042/1072 [10:21:03<17:23, 34.78s/it] 97%|█████████▋| 1043/1072 [10:21:38<16:46, 34.72s/it] 97%|█████████▋| 1044/1072 [10:22:12<16:09, 34.61s/it] 97%|█████████▋| 1045/1072 [10:22:47<15:34, 34.63s/it] 98%|█████████▊| 1046/1072 [10:23:21<15:00, 34.65s/it] 98%|█████████▊| 1047/1072 [10:23:56<14:25, 34.64s/it] 98%|█████████▊| 1048/1072 [10:24:30<13:46, 34.45s/it] 98%|█████████▊| 1049/1072 [10:25:05<13:15, 34.59s/it] 98%|█████████▊| 1050/1072 [10:25:40<12:44, 34.73s/it]                                                      {'loss': 1.7892, 'learning_rate': 1e-05, 'epoch': 1.96} 98%|█████████▊| 1050/1072 [10:25:40<12:44, 34.73s/it] 98%|█████████▊| 1051/1072 [10:26:15<12:12, 34.87s/it] 98%|█████████▊| 1052/1072 [10:26:50<11:39, 34.97s/it] 98%|█████████▊| 1053/1072 [10:27:25<11:04, 34.98s/it] 98%|█████████▊| 1054/1072 [10:28:00<10:29, 34.97s/it] 98%|█████████▊| 1055/1072 [10:28:35<09:53, 34.92s/it] 99%|█████████▊| 1056/1072 [10:29:10<09:18, 34.94s/it] 99%|█████████▊| 1057/1072 [10:29:45<08:43, 34.89s/it] 99%|█████████▊| 1058/1072 [10:30:19<08:06, 34.75s/it] 99%|█████████▉| 1059/1072 [10:30:54<07:31, 34.73s/it] 99%|█████████▉| 1060/1072 [10:31:29<06:56, 34.70s/it]                                                      {'loss': 1.8104, 'learning_rate': 1e-05, 'epoch': 1.98} 99%|█████████▉| 1060/1072 [10:31:29<06:56, 34.70s/it] 99%|█████████▉| 1061/1072 [10:32:04<06:22, 34.79s/it] 99%|█████████▉| 1062/1072 [10:32:39<05:48, 34.88s/it] 99%|█████████▉| 1063/1072 [10:33:13<05:13, 34.82s/it] 99%|█████████▉| 1064/1072 [10:33:48<04:37, 34.72s/it] 99%|█████████▉| 1065/1072 [10:34:22<04:02, 34.67s/it] 99%|█████████▉| 1066/1072 [10:34:57<03:27, 34.64s/it]100%|█████████▉| 1067/1072 [10:35:31<02:52, 34.48s/it]100%|█████████▉| 1068/1072 [10:36:06<02:18, 34.58s/it]100%|█████████▉| 1069/1072 [10:36:40<01:43, 34.49s/it]100%|█████████▉| 1070/1072 [10:37:14<01:08, 34.43s/it]                                                      {'loss': 1.7946, 'learning_rate': 1e-05, 'epoch': 1.99}100%|█████████▉| 1070/1072 [10:37:14<01:08, 34.43s/it]100%|█████████▉| 1071/1072 [10:37:49<00:34, 34.33s/it]100%|██████████| 1072/1072 [10:38:23<00:00, 34.40s/it]                                                      {'train_runtime': 38306.3615, 'train_samples_per_second': 4.033, 'train_steps_per_second': 0.028, 'train_loss': 1.9738694998755384, 'epoch': 2.0}100%|██████████| 1072/1072 [10:38:26<00:00, 34.40s/it]100%|██████████| 1072/1072 [10:38:26<00:00, 35.73s/it][2023-11-24 15:30:20,311] [INFO] [launch.py:347:main] Process 7628 exits successfully.***** train metrics *****  epoch                    =         2.0  train_loss               =      1.9739  train_runtime            = 10:38:26.36  train_samples_per_second =       4.033  train_steps_per_second   =       0.028[2023-11-24 15:30:24,316] [INFO] [launch.py:347:main] Process 7627 exits successfully.[2023-11-24 15:30:35,328] [INFO] [launch.py:347:main] Process 7626 exits successfully./usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/miniconda3/envs/llm_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...  warn(msg)/usr/local/miniconda3/envs/llm_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.Either way, this might cause trouble in the future:If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.  warn(msg)